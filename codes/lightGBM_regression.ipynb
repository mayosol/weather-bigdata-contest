{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "second-allowance",
   "metadata": {},
   "source": [
    "## 총판 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "declared-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_test = pd.read_csv(r'./X_test_weather_columns_6.csv', encoding='EUC-KR')\n",
    "X_train = pd.read_csv(r'./X_train_weather_columns_6.csv', encoding='EUC-KR')\n",
    "\n",
    "y_test = pd.read_csv(r'./y_test_weather_columns_6.csv', encoding='EUC-KR')\n",
    "y_train = pd.read_csv(r'./y_train_weather_columns_6.csv', encoding='EUC-KR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comic-germany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20대 남성 판매량(개)</th>\n",
       "      <th>20대 여성 판매량(개)</th>\n",
       "      <th>30대 남성 판매량(개)</th>\n",
       "      <th>30대 여성 판매량(개)</th>\n",
       "      <th>40대 남성 판매량(개)</th>\n",
       "      <th>40대 여성 판매량(개)</th>\n",
       "      <th>50대 남성 판매량(개)</th>\n",
       "      <th>50대 여성 판매량(개)</th>\n",
       "      <th>60대 남성 판매량(개)</th>\n",
       "      <th>60대 여성 판매량(개)</th>\n",
       "      <th>...</th>\n",
       "      <th>20대 남성 선호도 점수</th>\n",
       "      <th>20대 여성 선호도 점수</th>\n",
       "      <th>30대 남성 선호도 점수</th>\n",
       "      <th>30대 여성 선호도 점수</th>\n",
       "      <th>40대 남성 선호도 점수</th>\n",
       "      <th>40대 여성 선호도 점수</th>\n",
       "      <th>50대 남성 선호도 점수</th>\n",
       "      <th>50대 여성 선호도 점수</th>\n",
       "      <th>60대 남성 선호도 점수</th>\n",
       "      <th>60대 여성 선호도 점수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041312</td>\n",
       "      <td>0.113754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060858</td>\n",
       "      <td>0.112415</td>\n",
       "      <td>0.124614</td>\n",
       "      <td>0.262377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092382</td>\n",
       "      <td>0.104007</td>\n",
       "      <td>0.071597</td>\n",
       "      <td>0.109999</td>\n",
       "      <td>0.091931</td>\n",
       "      <td>0.106132</td>\n",
       "      <td>0.125492</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.097320</td>\n",
       "      <td>0.143339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119632</td>\n",
       "      <td>0.338576</td>\n",
       "      <td>0.128006</td>\n",
       "      <td>0.413786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054057</td>\n",
       "      <td>0.087421</td>\n",
       "      <td>0.115681</td>\n",
       "      <td>0.026710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>0.119883</td>\n",
       "      <td>0.056268</td>\n",
       "      <td>0.107681</td>\n",
       "      <td>0.086296</td>\n",
       "      <td>0.174232</td>\n",
       "      <td>0.102733</td>\n",
       "      <td>0.164393</td>\n",
       "      <td>0.038242</td>\n",
       "      <td>0.122037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56263</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367905</td>\n",
       "      <td>0.124260</td>\n",
       "      <td>0.171079</td>\n",
       "      <td>0.069168</td>\n",
       "      <td>0.183054</td>\n",
       "      <td>0.084533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56264</th>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109225</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.114278</td>\n",
       "      <td>0.146310</td>\n",
       "      <td>0.135864</td>\n",
       "      <td>0.069015</td>\n",
       "      <td>0.069549</td>\n",
       "      <td>0.036609</td>\n",
       "      <td>0.172594</td>\n",
       "      <td>0.063552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56265</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028774</td>\n",
       "      <td>0.087465</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>0.097373</td>\n",
       "      <td>0.128849</td>\n",
       "      <td>0.112391</td>\n",
       "      <td>0.029315</td>\n",
       "      <td>0.154307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56266</th>\n",
       "      <td>6.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086716</td>\n",
       "      <td>0.288002</td>\n",
       "      <td>0.047044</td>\n",
       "      <td>0.127707</td>\n",
       "      <td>0.028764</td>\n",
       "      <td>0.073057</td>\n",
       "      <td>0.088346</td>\n",
       "      <td>0.046504</td>\n",
       "      <td>0.045675</td>\n",
       "      <td>0.168184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56267</th>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025021</td>\n",
       "      <td>0.018592</td>\n",
       "      <td>0.039559</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>0.087386</td>\n",
       "      <td>0.119811</td>\n",
       "      <td>0.166387</td>\n",
       "      <td>0.173966</td>\n",
       "      <td>0.267876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56268 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       20대 남성 판매량(개)  20대 여성 판매량(개)  30대 남성 판매량(개)  30대 여성 판매량(개)  \\\n",
       "0                0.0            1.0            2.0            0.0   \n",
       "1                6.0           20.0           10.0           38.0   \n",
       "2                0.0            0.0            1.0            7.0   \n",
       "3                3.0            0.0            1.0            4.0   \n",
       "4                7.0           88.0           30.0          142.0   \n",
       "...              ...            ...            ...            ...   \n",
       "56263            1.0            1.0            1.0            1.0   \n",
       "56264            8.0           18.0           18.0           57.0   \n",
       "56265            1.0            9.0            7.0           18.0   \n",
       "56266            6.0           59.0            7.0           47.0   \n",
       "56267           10.0           22.0           34.0           70.0   \n",
       "\n",
       "       40대 남성 판매량(개)  40대 여성 판매량(개)  50대 남성 판매량(개)  50대 여성 판매량(개)  \\\n",
       "0                1.0            4.0            1.0            4.0   \n",
       "1               12.0           30.0            8.0            7.0   \n",
       "2                1.0            7.0            0.0            0.0   \n",
       "3                2.0            1.0            0.0            0.0   \n",
       "4               43.0          188.0           25.0           76.0   \n",
       "...              ...            ...            ...            ...   \n",
       "56263            1.0            1.0            0.0            0.0   \n",
       "56264           20.0           22.0            5.0            5.0   \n",
       "56265            9.0           17.0            1.0           10.0   \n",
       "56266            4.0           22.0            6.0            6.0   \n",
       "56267           55.0          152.0           47.0          124.0   \n",
       "\n",
       "       60대 남성 판매량(개)  60대 여성 판매량(개)  ...  20대 남성 선호도 점수  20대 여성 선호도 점수  \\\n",
       "0                0.0            1.0  ...       0.000000       0.041312   \n",
       "1                2.0            4.0  ...       0.092382       0.104007   \n",
       "2                0.0            0.0  ...       0.000000       0.000000   \n",
       "3                1.0            0.0  ...       0.348746       0.000000   \n",
       "4                3.0           13.0  ...       0.028234       0.119883   \n",
       "...              ...            ...  ...            ...            ...   \n",
       "56263            0.0            0.0  ...       0.367905       0.124260   \n",
       "56264            4.0            2.0  ...       0.109225       0.083004   \n",
       "56265            0.0            4.0  ...       0.028774       0.087465   \n",
       "56266            1.0            5.0  ...       0.086716       0.288002   \n",
       "56267           22.0           46.0  ...       0.025021       0.018592   \n",
       "\n",
       "       30대 남성 선호도 점수  30대 여성 선호도 점수  40대 남성 선호도 점수  40대 여성 선호도 점수  \\\n",
       "0           0.113754       0.000000       0.060858       0.112415   \n",
       "1           0.071597       0.109999       0.091931       0.106132   \n",
       "2           0.119632       0.338576       0.128006       0.413786   \n",
       "3           0.054057       0.087421       0.115681       0.026710   \n",
       "4           0.056268       0.107681       0.086296       0.174232   \n",
       "...              ...            ...            ...            ...   \n",
       "56263       0.171079       0.069168       0.183054       0.084533   \n",
       "56264       0.114278       0.146310       0.135864       0.069015   \n",
       "56265       0.093660       0.097373       0.128849       0.112391   \n",
       "56266       0.047044       0.127707       0.028764       0.073057   \n",
       "56267       0.039559       0.032929       0.068472       0.087386   \n",
       "\n",
       "       50대 남성 선호도 점수  50대 여성 선호도 점수  60대 남성 선호도 점수  60대 여성 선호도 점수  \n",
       "0           0.124614       0.262377       0.000000       0.284671  \n",
       "1           0.125492       0.057800       0.097320       0.143339  \n",
       "2           0.000000       0.000000       0.000000       0.000000  \n",
       "3           0.000000       0.000000       0.367385       0.000000  \n",
       "4           0.102733       0.164393       0.038242       0.122037  \n",
       "...              ...            ...            ...            ...  \n",
       "56263       0.000000       0.000000       0.000000       0.000000  \n",
       "56264       0.069549       0.036609       0.172594       0.063552  \n",
       "56265       0.029315       0.154307       0.000000       0.267868  \n",
       "56266       0.088346       0.046504       0.045675       0.168184  \n",
       "56267       0.119811       0.166387       0.173966       0.267876  \n",
       "\n",
       "[56268 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protecting-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "convenient-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': ['l2', 'auc'],\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 10,\n",
    "    'verbose': 0,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_leaves\": 128,  \n",
    "    \"max_bin\": 512,\n",
    "    \"num_iterations\": 250,\n",
    "    \"n_estimators\": 400\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "local-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMRegressor(**hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "local-momentum",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\redem\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's l1: 189.581\tvalid_0's l2: 119231\tvalid_0's auc: 1\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's l1: 188.614\tvalid_0's l2: 117510\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's l1: 187.659\tvalid_0's l2: 115821\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's l1: 186.713\tvalid_0's l2: 114160\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's l1: 185.809\tvalid_0's l2: 112572\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's l1: 184.885\tvalid_0's l2: 110980\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's l1: 183.969\tvalid_0's l2: 109416\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's l1: 183.08\tvalid_0's l2: 107904\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's l1: 182.399\tvalid_0's l2: 107012\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's l1: 181.515\tvalid_0's l2: 105537\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's l1: 180.655\tvalid_0's l2: 104103\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's l1: 179.899\tvalid_0's l2: 102878\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's l1: 179.045\tvalid_0's l2: 101483\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's l1: 178.215\tvalid_0's l2: 100131\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's l1: 177.395\tvalid_0's l2: 98804.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's l1: 176.568\tvalid_0's l2: 97491\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's l1: 176.03\tvalid_0's l2: 96812.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's l1: 175.249\tvalid_0's l2: 95597.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's l1: 174.446\tvalid_0's l2: 94349.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's l1: 173.651\tvalid_0's l2: 93123.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's l1: 172.858\tvalid_0's l2: 91900.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's l1: 172.103\tvalid_0's l2: 90758.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's l1: 171.34\tvalid_0's l2: 89602.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's l1: 170.726\tvalid_0's l2: 88809\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's l1: 170.144\tvalid_0's l2: 88080\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's l1: 169.542\tvalid_0's l2: 87321\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's l1: 168.805\tvalid_0's l2: 86230.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's l1: 168.077\tvalid_0's l2: 85161.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's l1: 167.343\tvalid_0's l2: 84093.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's l1: 166.629\tvalid_0's l2: 83074.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's l1: 165.925\tvalid_0's l2: 82087\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's l1: 165.382\tvalid_0's l2: 81470.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's l1: 164.692\tvalid_0's l2: 80500.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's l1: 164.002\tvalid_0's l2: 79552\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's l1: 163.452\tvalid_0's l2: 78906.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's l1: 162.781\tvalid_0's l2: 78000.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's l1: 162.119\tvalid_0's l2: 77107.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's l1: 161.462\tvalid_0's l2: 76231.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's l1: 160.814\tvalid_0's l2: 75366\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's l1: 160.174\tvalid_0's l2: 74525.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's l1: 159.54\tvalid_0's l2: 73694.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's l1: 159.097\tvalid_0's l2: 73219.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's l1: 158.475\tvalid_0's l2: 72413.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's l1: 157.859\tvalid_0's l2: 71618.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's l1: 157.268\tvalid_0's l2: 70878.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's l1: 156.669\tvalid_0's l2: 70120.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's l1: 156.073\tvalid_0's l2: 69370.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's l1: 155.491\tvalid_0's l2: 68646.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's l1: 154.912\tvalid_0's l2: 67929.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's l1: 154.445\tvalid_0's l2: 67445.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's l1: 153.931\tvalid_0's l2: 66828.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's l1: 153.479\tvalid_0's l2: 66392.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's l1: 152.984\tvalid_0's l2: 65806.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's l1: 152.53\tvalid_0's l2: 65349\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's l1: 151.982\tvalid_0's l2: 64695.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[56]\tvalid_0's l1: 151.433\tvalid_0's l2: 64045.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's l1: 150.9\tvalid_0's l2: 63427.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's l1: 150.567\tvalid_0's l2: 63225\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[59]\tvalid_0's l1: 150.095\tvalid_0's l2: 62690.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's l1: 149.574\tvalid_0's l2: 62090.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\tvalid_0's l1: 149.046\tvalid_0's l2: 61486.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\tvalid_0's l1: 148.524\tvalid_0's l2: 60898.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[63]\tvalid_0's l1: 148.01\tvalid_0's l2: 60319.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\tvalid_0's l1: 147.496\tvalid_0's l2: 59744.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tvalid_0's l1: 146.994\tvalid_0's l2: 59188.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's l1: 146.594\tvalid_0's l2: 58830.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tvalid_0's l1: 146.102\tvalid_0's l2: 58284.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's l1: 145.714\tvalid_0's l2: 57941.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[69]\tvalid_0's l1: 145.231\tvalid_0's l2: 57411.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's l1: 144.754\tvalid_0's l2: 56901\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's l1: 144.32\tvalid_0's l2: 56448.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tvalid_0's l1: 143.851\tvalid_0's l2: 55957.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\tvalid_0's l1: 143.393\tvalid_0's l2: 55482.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's l1: 142.926\tvalid_0's l2: 54997.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's l1: 142.472\tvalid_0's l2: 54525\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tvalid_0's l1: 142.119\tvalid_0's l2: 54232.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tvalid_0's l1: 141.674\tvalid_0's l2: 53776.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\tvalid_0's l1: 141.234\tvalid_0's l2: 53325.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[79]\tvalid_0's l1: 140.802\tvalid_0's l2: 52890.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's l1: 140.379\tvalid_0's l2: 52465.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tvalid_0's l1: 139.957\tvalid_0's l2: 52050.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\tvalid_0's l1: 139.535\tvalid_0's l2: 51644.8\tvalid_0's auc: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[83]\tvalid_0's l1: 139.124\tvalid_0's l2: 51246.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[84]\tvalid_0's l1: 138.713\tvalid_0's l2: 50851.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\tvalid_0's l1: 138.307\tvalid_0's l2: 50468.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[86]\tvalid_0's l1: 137.906\tvalid_0's l2: 50086.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[87]\tvalid_0's l1: 137.509\tvalid_0's l2: 49716.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\tvalid_0's l1: 137.115\tvalid_0's l2: 49357.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[89]\tvalid_0's l1: 136.73\tvalid_0's l2: 48997.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's l1: 136.343\tvalid_0's l2: 48648.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[91]\tvalid_0's l1: 136.036\tvalid_0's l2: 48415.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[92]\tvalid_0's l1: 135.719\tvalid_0's l2: 48165.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[93]\tvalid_0's l1: 135.348\tvalid_0's l2: 47820.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[94]\tvalid_0's l1: 134.979\tvalid_0's l2: 47493.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[95]\tvalid_0's l1: 134.609\tvalid_0's l2: 47155.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[96]\tvalid_0's l1: 134.244\tvalid_0's l2: 46826.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[97]\tvalid_0's l1: 133.883\tvalid_0's l2: 46504.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[98]\tvalid_0's l1: 133.586\tvalid_0's l2: 46282.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[99]\tvalid_0's l1: 133.294\tvalid_0's l2: 46075.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's l1: 132.935\tvalid_0's l2: 45772.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[101]\tvalid_0's l1: 132.587\tvalid_0's l2: 45479.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[102]\tvalid_0's l1: 132.244\tvalid_0's l2: 45186.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[103]\tvalid_0's l1: 131.91\tvalid_0's l2: 44900.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[104]\tvalid_0's l1: 131.576\tvalid_0's l2: 44626.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[105]\tvalid_0's l1: 131.25\tvalid_0's l2: 44357.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[106]\tvalid_0's l1: 130.912\tvalid_0's l2: 44092.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[107]\tvalid_0's l1: 130.594\tvalid_0's l2: 43835.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[108]\tvalid_0's l1: 130.312\tvalid_0's l2: 43641.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[109]\tvalid_0's l1: 130.059\tvalid_0's l2: 43474.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[110]\tvalid_0's l1: 129.741\tvalid_0's l2: 43222.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[111]\tvalid_0's l1: 129.432\tvalid_0's l2: 42974\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[112]\tvalid_0's l1: 129.18\tvalid_0's l2: 42807.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[113]\tvalid_0's l1: 128.86\tvalid_0's l2: 42562.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[114]\tvalid_0's l1: 128.548\tvalid_0's l2: 42325.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[115]\tvalid_0's l1: 128.237\tvalid_0's l2: 42093\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[116]\tvalid_0's l1: 127.934\tvalid_0's l2: 41855.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[117]\tvalid_0's l1: 127.637\tvalid_0's l2: 41634.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[118]\tvalid_0's l1: 127.349\tvalid_0's l2: 41414.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[119]\tvalid_0's l1: 127.071\tvalid_0's l2: 41217\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\tvalid_0's l1: 126.783\tvalid_0's l2: 41002.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[121]\tvalid_0's l1: 126.483\tvalid_0's l2: 40786.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[122]\tvalid_0's l1: 126.18\tvalid_0's l2: 40570.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[123]\tvalid_0's l1: 125.903\tvalid_0's l2: 40376.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[124]\tvalid_0's l1: 125.61\tvalid_0's l2: 40167.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[125]\tvalid_0's l1: 125.323\tvalid_0's l2: 39965.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[126]\tvalid_0's l1: 125.039\tvalid_0's l2: 39768.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[127]\tvalid_0's l1: 124.775\tvalid_0's l2: 39585.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[128]\tvalid_0's l1: 124.493\tvalid_0's l2: 39397.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[129]\tvalid_0's l1: 124.241\tvalid_0's l2: 39223.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[130]\tvalid_0's l1: 123.967\tvalid_0's l2: 39043.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[131]\tvalid_0's l1: 123.728\tvalid_0's l2: 38912.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[132]\tvalid_0's l1: 123.47\tvalid_0's l2: 38739.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[133]\tvalid_0's l1: 123.212\tvalid_0's l2: 38568.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[134]\tvalid_0's l1: 122.976\tvalid_0's l2: 38412.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[135]\tvalid_0's l1: 122.725\tvalid_0's l2: 38246.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[136]\tvalid_0's l1: 122.481\tvalid_0's l2: 38084.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[137]\tvalid_0's l1: 122.232\tvalid_0's l2: 37926.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[138]\tvalid_0's l1: 121.998\tvalid_0's l2: 37772.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[139]\tvalid_0's l1: 121.76\tvalid_0's l2: 37623\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\tvalid_0's l1: 121.553\tvalid_0's l2: 37482.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[141]\tvalid_0's l1: 121.328\tvalid_0's l2: 37327.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[142]\tvalid_0's l1: 121.121\tvalid_0's l2: 37207.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[143]\tvalid_0's l1: 120.899\tvalid_0's l2: 37059.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[144]\tvalid_0's l1: 120.674\tvalid_0's l2: 36909.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[145]\tvalid_0's l1: 120.483\tvalid_0's l2: 36806.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[146]\tvalid_0's l1: 120.265\tvalid_0's l2: 36665.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[147]\tvalid_0's l1: 120.047\tvalid_0's l2: 36521.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[148]\tvalid_0's l1: 119.831\tvalid_0's l2: 36380.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[149]\tvalid_0's l1: 119.625\tvalid_0's l2: 36249.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tvalid_0's l1: 119.413\tvalid_0's l2: 36118.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[151]\tvalid_0's l1: 119.196\tvalid_0's l2: 35984.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[152]\tvalid_0's l1: 118.993\tvalid_0's l2: 35876.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[153]\tvalid_0's l1: 118.788\tvalid_0's l2: 35754.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[154]\tvalid_0's l1: 118.579\tvalid_0's l2: 35623.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[155]\tvalid_0's l1: 118.365\tvalid_0's l2: 35496.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[156]\tvalid_0's l1: 118.154\tvalid_0's l2: 35373.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[157]\tvalid_0's l1: 117.946\tvalid_0's l2: 35251.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[158]\tvalid_0's l1: 117.747\tvalid_0's l2: 35129.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[159]\tvalid_0's l1: 117.541\tvalid_0's l2: 35009.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[160]\tvalid_0's l1: 117.352\tvalid_0's l2: 34894.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[161]\tvalid_0's l1: 117.149\tvalid_0's l2: 34782.8\tvalid_0's auc: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[162]\tvalid_0's l1: 116.95\tvalid_0's l2: 34671.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[163]\tvalid_0's l1: 116.756\tvalid_0's l2: 34565.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[164]\tvalid_0's l1: 116.563\tvalid_0's l2: 34458.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[165]\tvalid_0's l1: 116.382\tvalid_0's l2: 34358.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[166]\tvalid_0's l1: 116.199\tvalid_0's l2: 34257.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[167]\tvalid_0's l1: 116.003\tvalid_0's l2: 34158.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[168]\tvalid_0's l1: 115.81\tvalid_0's l2: 34058.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[169]\tvalid_0's l1: 115.63\tvalid_0's l2: 33964.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[170]\tvalid_0's l1: 115.446\tvalid_0's l2: 33866.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[171]\tvalid_0's l1: 115.261\tvalid_0's l2: 33771.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[172]\tvalid_0's l1: 115.079\tvalid_0's l2: 33681.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[173]\tvalid_0's l1: 114.906\tvalid_0's l2: 33585.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[174]\tvalid_0's l1: 114.741\tvalid_0's l2: 33495.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[175]\tvalid_0's l1: 114.578\tvalid_0's l2: 33412.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[176]\tvalid_0's l1: 114.419\tvalid_0's l2: 33325.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[177]\tvalid_0's l1: 114.247\tvalid_0's l2: 33240.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[178]\tvalid_0's l1: 114.099\tvalid_0's l2: 33168.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[179]\tvalid_0's l1: 113.937\tvalid_0's l2: 33081.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[180]\tvalid_0's l1: 113.773\tvalid_0's l2: 32999.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[181]\tvalid_0's l1: 113.609\tvalid_0's l2: 32930.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[182]\tvalid_0's l1: 113.446\tvalid_0's l2: 32857\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[183]\tvalid_0's l1: 113.285\tvalid_0's l2: 32780.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[184]\tvalid_0's l1: 113.125\tvalid_0's l2: 32708.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[185]\tvalid_0's l1: 112.964\tvalid_0's l2: 32634.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[186]\tvalid_0's l1: 112.813\tvalid_0's l2: 32562.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[187]\tvalid_0's l1: 112.664\tvalid_0's l2: 32506\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[188]\tvalid_0's l1: 112.508\tvalid_0's l2: 32435.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[189]\tvalid_0's l1: 112.362\tvalid_0's l2: 32367.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[190]\tvalid_0's l1: 112.217\tvalid_0's l2: 32302.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[191]\tvalid_0's l1: 112.077\tvalid_0's l2: 32229.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[192]\tvalid_0's l1: 111.936\tvalid_0's l2: 32153.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[193]\tvalid_0's l1: 111.794\tvalid_0's l2: 32083.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[194]\tvalid_0's l1: 111.663\tvalid_0's l2: 32029.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[195]\tvalid_0's l1: 111.526\tvalid_0's l2: 31957.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[196]\tvalid_0's l1: 111.393\tvalid_0's l2: 31892.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[197]\tvalid_0's l1: 111.257\tvalid_0's l2: 31824.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[198]\tvalid_0's l1: 111.129\tvalid_0's l2: 31763.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[199]\tvalid_0's l1: 110.984\tvalid_0's l2: 31695.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's l1: 110.858\tvalid_0's l2: 31639.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[201]\tvalid_0's l1: 110.712\tvalid_0's l2: 31574.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[202]\tvalid_0's l1: 110.566\tvalid_0's l2: 31514.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[203]\tvalid_0's l1: 110.429\tvalid_0's l2: 31466.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[204]\tvalid_0's l1: 110.307\tvalid_0's l2: 31418.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[205]\tvalid_0's l1: 110.176\tvalid_0's l2: 31363.8\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[206]\tvalid_0's l1: 110.037\tvalid_0's l2: 31308.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[207]\tvalid_0's l1: 109.908\tvalid_0's l2: 31246\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[208]\tvalid_0's l1: 109.792\tvalid_0's l2: 31185.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[209]\tvalid_0's l1: 109.655\tvalid_0's l2: 31125.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[210]\tvalid_0's l1: 109.539\tvalid_0's l2: 31064\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[211]\tvalid_0's l1: 109.411\tvalid_0's l2: 31012.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[212]\tvalid_0's l1: 109.288\tvalid_0's l2: 30959.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[213]\tvalid_0's l1: 109.166\tvalid_0's l2: 30908.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[214]\tvalid_0's l1: 109.046\tvalid_0's l2: 30857.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[215]\tvalid_0's l1: 108.926\tvalid_0's l2: 30810.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[216]\tvalid_0's l1: 108.815\tvalid_0's l2: 30757.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[217]\tvalid_0's l1: 108.689\tvalid_0's l2: 30707\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[218]\tvalid_0's l1: 108.576\tvalid_0's l2: 30654.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[219]\tvalid_0's l1: 108.466\tvalid_0's l2: 30606.2\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[220]\tvalid_0's l1: 108.352\tvalid_0's l2: 30560.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[221]\tvalid_0's l1: 108.227\tvalid_0's l2: 30499.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[222]\tvalid_0's l1: 108.109\tvalid_0's l2: 30443.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[223]\tvalid_0's l1: 107.99\tvalid_0's l2: 30380.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[224]\tvalid_0's l1: 107.876\tvalid_0's l2: 30318.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[225]\tvalid_0's l1: 107.761\tvalid_0's l2: 30254.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[226]\tvalid_0's l1: 107.641\tvalid_0's l2: 30193.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[227]\tvalid_0's l1: 107.528\tvalid_0's l2: 30137.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[228]\tvalid_0's l1: 107.409\tvalid_0's l2: 30079.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[229]\tvalid_0's l1: 107.299\tvalid_0's l2: 30025.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[230]\tvalid_0's l1: 107.186\tvalid_0's l2: 29977.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[231]\tvalid_0's l1: 107.063\tvalid_0's l2: 29933.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[232]\tvalid_0's l1: 106.943\tvalid_0's l2: 29891.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[233]\tvalid_0's l1: 106.829\tvalid_0's l2: 29850.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[234]\tvalid_0's l1: 106.706\tvalid_0's l2: 29806.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[235]\tvalid_0's l1: 106.592\tvalid_0's l2: 29768.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[236]\tvalid_0's l1: 106.474\tvalid_0's l2: 29729.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[237]\tvalid_0's l1: 106.368\tvalid_0's l2: 29691.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[238]\tvalid_0's l1: 106.253\tvalid_0's l2: 29652.6\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[239]\tvalid_0's l1: 106.14\tvalid_0's l2: 29615.5\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[240]\tvalid_0's l1: 106.041\tvalid_0's l2: 29580.9\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[241]\tvalid_0's l1: 105.946\tvalid_0's l2: 29538.2\tvalid_0's auc: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[242]\tvalid_0's l1: 105.852\tvalid_0's l2: 29496.4\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[243]\tvalid_0's l1: 105.755\tvalid_0's l2: 29458.7\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[244]\tvalid_0's l1: 105.654\tvalid_0's l2: 29419.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[245]\tvalid_0's l1: 105.545\tvalid_0's l2: 29381.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[246]\tvalid_0's l1: 105.446\tvalid_0's l2: 29345.1\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[247]\tvalid_0's l1: 105.344\tvalid_0's l2: 29308.3\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[248]\tvalid_0's l1: 105.249\tvalid_0's l2: 29274\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[249]\tvalid_0's l1: 105.148\tvalid_0's l2: 29239\tvalid_0's auc: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[250]\tvalid_0's l1: 105.051\tvalid_0's l2: 29203.3\tvalid_0's auc: 1\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[250]\tvalid_0's l1: 105.051\tvalid_0's l2: 29203.3\tvalid_0's auc: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.7, bagging_freq=10, feature_fraction=0.9,\n",
       "              learning_rate=0.01, max_bin=512, max_depth=8,\n",
       "              metric=['l2', 'auc'], n_estimators=400, num_iterations=250,\n",
       "              num_leaves=128, objective='regression', task='train', verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['합계']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['합계']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "certified-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "equivalent-works",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 157.35224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('The rmse of prediction is:', round(mean_squared_error(y_pred, np.array(y_train['합계'])) ** 0.5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "common-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/lasmith/house-price-regression-with-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "raising-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pediatric-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 175.605\tvalid_0's l2: 102529\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 162.539\tvalid_0's l2: 87657.7\n",
      "[3]\tvalid_0's l1: 151.35\tvalid_0's l2: 75568.3\n",
      "[4]\tvalid_0's l1: 141.32\tvalid_0's l2: 65807.7\n",
      "[5]\tvalid_0's l1: 132.889\tvalid_0's l2: 57873.5\n",
      "[6]\tvalid_0's l1: 125.476\tvalid_0's l2: 51446.4\n",
      "[7]\tvalid_0's l1: 119.412\tvalid_0's l2: 46256\n",
      "[8]\tvalid_0's l1: 114.219\tvalid_0's l2: 42096.1\n",
      "[9]\tvalid_0's l1: 109.428\tvalid_0's l2: 38633.6\n",
      "[10]\tvalid_0's l1: 105.515\tvalid_0's l2: 35856.6\n",
      "[11]\tvalid_0's l1: 102.116\tvalid_0's l2: 33562\n",
      "[12]\tvalid_0's l1: 99.0817\tvalid_0's l2: 31705.6\n",
      "[13]\tvalid_0's l1: 96.6924\tvalid_0's l2: 30194.2\n",
      "[14]\tvalid_0's l1: 94.5212\tvalid_0's l2: 28925.3\n",
      "[15]\tvalid_0's l1: 92.4048\tvalid_0's l2: 27877.2\n",
      "[16]\tvalid_0's l1: 90.8322\tvalid_0's l2: 27041.5\n",
      "[17]\tvalid_0's l1: 89.4105\tvalid_0's l2: 26312.7\n",
      "[18]\tvalid_0's l1: 88.0434\tvalid_0's l2: 25732.6\n",
      "[19]\tvalid_0's l1: 86.684\tvalid_0's l2: 25193\n",
      "[20]\tvalid_0's l1: 85.662\tvalid_0's l2: 24775.9\n",
      "[21]\tvalid_0's l1: 84.4476\tvalid_0's l2: 24368.9\n",
      "[22]\tvalid_0's l1: 83.5708\tvalid_0's l2: 24071\n",
      "[23]\tvalid_0's l1: 82.5362\tvalid_0's l2: 23746.4\n",
      "[24]\tvalid_0's l1: 81.5165\tvalid_0's l2: 23487.8\n",
      "[25]\tvalid_0's l1: 80.8772\tvalid_0's l2: 23284.7\n",
      "[26]\tvalid_0's l1: 80.043\tvalid_0's l2: 23036.5\n",
      "[27]\tvalid_0's l1: 79.5629\tvalid_0's l2: 22904.9\n",
      "[28]\tvalid_0's l1: 78.6492\tvalid_0's l2: 22661.1\n",
      "[29]\tvalid_0's l1: 78.0928\tvalid_0's l2: 22532.9\n",
      "[30]\tvalid_0's l1: 77.4884\tvalid_0's l2: 22370.5\n",
      "[31]\tvalid_0's l1: 76.6399\tvalid_0's l2: 22222.3\n",
      "[32]\tvalid_0's l1: 76.2093\tvalid_0's l2: 22108.6\n",
      "[33]\tvalid_0's l1: 75.7735\tvalid_0's l2: 21988\n",
      "[34]\tvalid_0's l1: 75.4982\tvalid_0's l2: 21925.1\n",
      "[35]\tvalid_0's l1: 75.2076\tvalid_0's l2: 21866.6\n",
      "[36]\tvalid_0's l1: 74.9387\tvalid_0's l2: 21772.7\n",
      "[37]\tvalid_0's l1: 74.3337\tvalid_0's l2: 21616.2\n",
      "[38]\tvalid_0's l1: 73.763\tvalid_0's l2: 21524.1\n",
      "[39]\tvalid_0's l1: 73.5636\tvalid_0's l2: 21448\n",
      "[40]\tvalid_0's l1: 72.9039\tvalid_0's l2: 21351.2\n",
      "[41]\tvalid_0's l1: 72.6101\tvalid_0's l2: 21285.9\n",
      "[42]\tvalid_0's l1: 72.0902\tvalid_0's l2: 21138.4\n",
      "[43]\tvalid_0's l1: 71.4962\tvalid_0's l2: 21058.4\n",
      "[44]\tvalid_0's l1: 71.1314\tvalid_0's l2: 20988.2\n",
      "[45]\tvalid_0's l1: 70.8065\tvalid_0's l2: 20925.3\n",
      "[46]\tvalid_0's l1: 70.4689\tvalid_0's l2: 20861.4\n",
      "[47]\tvalid_0's l1: 70.2005\tvalid_0's l2: 20802.9\n",
      "[48]\tvalid_0's l1: 69.8194\tvalid_0's l2: 20720.4\n",
      "[49]\tvalid_0's l1: 69.4333\tvalid_0's l2: 20652.4\n",
      "[50]\tvalid_0's l1: 69.2102\tvalid_0's l2: 20606.7\n",
      "[51]\tvalid_0's l1: 69.0804\tvalid_0's l2: 20565.4\n",
      "[52]\tvalid_0's l1: 68.9034\tvalid_0's l2: 20521.8\n",
      "[53]\tvalid_0's l1: 68.5589\tvalid_0's l2: 20455.7\n",
      "[54]\tvalid_0's l1: 68.4122\tvalid_0's l2: 20441.6\n",
      "[55]\tvalid_0's l1: 68.281\tvalid_0's l2: 20395.2\n",
      "[56]\tvalid_0's l1: 68.0248\tvalid_0's l2: 20358.2\n",
      "[57]\tvalid_0's l1: 67.8199\tvalid_0's l2: 20325.3\n",
      "[58]\tvalid_0's l1: 67.6478\tvalid_0's l2: 20264\n",
      "[59]\tvalid_0's l1: 67.2616\tvalid_0's l2: 20218.7\n",
      "[60]\tvalid_0's l1: 66.932\tvalid_0's l2: 20175.4\n",
      "[61]\tvalid_0's l1: 66.7393\tvalid_0's l2: 20110.3\n",
      "[62]\tvalid_0's l1: 66.6144\tvalid_0's l2: 20077.6\n",
      "[63]\tvalid_0's l1: 66.4361\tvalid_0's l2: 20047.5\n",
      "[64]\tvalid_0's l1: 66.2551\tvalid_0's l2: 20017.7\n",
      "[65]\tvalid_0's l1: 65.9763\tvalid_0's l2: 19982.9\n",
      "[66]\tvalid_0's l1: 65.8414\tvalid_0's l2: 19954.3\n",
      "[67]\tvalid_0's l1: 65.712\tvalid_0's l2: 19929.6\n",
      "[68]\tvalid_0's l1: 65.4422\tvalid_0's l2: 19848.8\n",
      "[69]\tvalid_0's l1: 65.3072\tvalid_0's l2: 19804.3\n",
      "[70]\tvalid_0's l1: 65.1335\tvalid_0's l2: 19778.8\n",
      "[71]\tvalid_0's l1: 64.9813\tvalid_0's l2: 19752.9\n",
      "[72]\tvalid_0's l1: 64.7082\tvalid_0's l2: 19700.8\n",
      "[73]\tvalid_0's l1: 64.5556\tvalid_0's l2: 19654.7\n",
      "[74]\tvalid_0's l1: 64.4394\tvalid_0's l2: 19638.1\n",
      "[75]\tvalid_0's l1: 64.4088\tvalid_0's l2: 19653.4\n",
      "[76]\tvalid_0's l1: 64.2746\tvalid_0's l2: 19629.2\n",
      "[77]\tvalid_0's l1: 64.0891\tvalid_0's l2: 19601.5\n",
      "[78]\tvalid_0's l1: 63.9289\tvalid_0's l2: 19574.5\n",
      "[79]\tvalid_0's l1: 63.8623\tvalid_0's l2: 19552\n",
      "[80]\tvalid_0's l1: 63.829\tvalid_0's l2: 19557.5\n",
      "[81]\tvalid_0's l1: 63.762\tvalid_0's l2: 19553.5\n",
      "[82]\tvalid_0's l1: 63.6693\tvalid_0's l2: 19536.2\n",
      "[83]\tvalid_0's l1: 63.5285\tvalid_0's l2: 19513.3\n",
      "[84]\tvalid_0's l1: 63.4447\tvalid_0's l2: 19487.5\n",
      "[85]\tvalid_0's l1: 63.3941\tvalid_0's l2: 19474.2\n",
      "[86]\tvalid_0's l1: 63.2928\tvalid_0's l2: 19442.1\n",
      "[87]\tvalid_0's l1: 63.2091\tvalid_0's l2: 19433.5\n",
      "[88]\tvalid_0's l1: 63.1176\tvalid_0's l2: 19422\n",
      "[89]\tvalid_0's l1: 63.0412\tvalid_0's l2: 19411.9\n",
      "[90]\tvalid_0's l1: 62.9373\tvalid_0's l2: 19385.2\n",
      "[91]\tvalid_0's l1: 62.8433\tvalid_0's l2: 19348.3\n",
      "[92]\tvalid_0's l1: 62.763\tvalid_0's l2: 19328.7\n",
      "[93]\tvalid_0's l1: 62.6505\tvalid_0's l2: 19311.7\n",
      "[94]\tvalid_0's l1: 62.5473\tvalid_0's l2: 19294.4\n",
      "[95]\tvalid_0's l1: 62.5273\tvalid_0's l2: 19294.4\n",
      "[96]\tvalid_0's l1: 62.4839\tvalid_0's l2: 19288.8\n",
      "[97]\tvalid_0's l1: 62.399\tvalid_0's l2: 19269.2\n",
      "[98]\tvalid_0's l1: 62.311\tvalid_0's l2: 19249.2\n",
      "[99]\tvalid_0's l1: 62.279\tvalid_0's l2: 19245\n",
      "[100]\tvalid_0's l1: 62.2245\tvalid_0's l2: 19221\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 62.2245\tvalid_0's l2: 19221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['합계']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['합계']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ordered-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-withdrawal",
   "metadata": {},
   "source": [
    "## 선호도 점수 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "transparent-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eligible-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_score_test = pd.DataFrame(columns=['일별 물품 선호도 점수', '20대 남성 선호도 점수', '20대 여성 선호도 점수', '30대 남성 선호도 점수', '30대 여성 선호도 점수', '40대 남성 선호도 점수', '40대 여성 선호도 점수', '50대 남성 선호도 점수', '50대 여성 선호도 점수', '60대 남성 선호도 점수', '60대 여성 선호도 점수'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fluid-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_score_test = pd.DataFrame(columns=['20대 남성 선호도 점수', '20대 여성 선호도 점수', '30대 남성 선호도 점수', '30대 여성 선호도 점수', '40대 남성 선호도 점수', '40대 여성 선호도 점수', '50대 남성 선호도 점수', '50대 여성 선호도 점수', '60대 남성 선호도 점수', '60대 여성 선호도 점수'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "shared-employer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gbm.fit(X_train.iloc[:, 1:], np.array(y_train['일별 물품 선호도 점수']),\n",
    "#         eval_set=[(X_test.iloc[:, 1:], np.array(y_test['일별 물품 선호도 점수']))],\n",
    "#         eval_metric='l1',\n",
    "#         early_stopping_rounds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "convertible-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "# y_train_score_test['일별 물품 선호도 점수'] = y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "other-miller",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_train_score_test['일별 물품 선호도 점수'] = y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interested-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum += mean_squared_error(y_pred2, np.array(y_train['일별 물품 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "uniform-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum += k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "norman-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pharmaceutical-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-allocation",
   "metadata": {},
   "source": [
    "20대 남성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "loving-medicaid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0766661\tvalid_0's l2: 0.0131356\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 0.0746872\tvalid_0's l2: 0.0126839\n",
      "[3]\tvalid_0's l1: 0.0730298\tvalid_0's l2: 0.012321\n",
      "[4]\tvalid_0's l1: 0.0716106\tvalid_0's l2: 0.0120208\n",
      "[5]\tvalid_0's l1: 0.0704425\tvalid_0's l2: 0.0117804\n",
      "[6]\tvalid_0's l1: 0.0693413\tvalid_0's l2: 0.0115782\n",
      "[7]\tvalid_0's l1: 0.0684716\tvalid_0's l2: 0.0114141\n",
      "[8]\tvalid_0's l1: 0.0676006\tvalid_0's l2: 0.0112648\n",
      "[9]\tvalid_0's l1: 0.066911\tvalid_0's l2: 0.011152\n",
      "[10]\tvalid_0's l1: 0.0662285\tvalid_0's l2: 0.0110529\n",
      "[11]\tvalid_0's l1: 0.0656367\tvalid_0's l2: 0.010968\n",
      "[12]\tvalid_0's l1: 0.0651545\tvalid_0's l2: 0.0108984\n",
      "[13]\tvalid_0's l1: 0.0647352\tvalid_0's l2: 0.0108429\n",
      "[14]\tvalid_0's l1: 0.0643645\tvalid_0's l2: 0.0107974\n",
      "[15]\tvalid_0's l1: 0.06394\tvalid_0's l2: 0.0107478\n",
      "[16]\tvalid_0's l1: 0.0635681\tvalid_0's l2: 0.0107045\n",
      "[17]\tvalid_0's l1: 0.0632639\tvalid_0's l2: 0.0106701\n",
      "[18]\tvalid_0's l1: 0.0630771\tvalid_0's l2: 0.0106499\n",
      "[19]\tvalid_0's l1: 0.0629138\tvalid_0's l2: 0.0106221\n",
      "[20]\tvalid_0's l1: 0.0626747\tvalid_0's l2: 0.0106007\n",
      "[21]\tvalid_0's l1: 0.0625201\tvalid_0's l2: 0.0105793\n",
      "[22]\tvalid_0's l1: 0.0622843\tvalid_0's l2: 0.0105526\n",
      "[23]\tvalid_0's l1: 0.0620777\tvalid_0's l2: 0.0105298\n",
      "[24]\tvalid_0's l1: 0.0619344\tvalid_0's l2: 0.0105077\n",
      "[25]\tvalid_0's l1: 0.0618137\tvalid_0's l2: 0.0104939\n",
      "[26]\tvalid_0's l1: 0.0617803\tvalid_0's l2: 0.0104906\n",
      "[27]\tvalid_0's l1: 0.0615933\tvalid_0's l2: 0.0104718\n",
      "[28]\tvalid_0's l1: 0.0614986\tvalid_0's l2: 0.0104652\n",
      "[29]\tvalid_0's l1: 0.0614201\tvalid_0's l2: 0.010457\n",
      "[30]\tvalid_0's l1: 0.0612718\tvalid_0's l2: 0.0104506\n",
      "[31]\tvalid_0's l1: 0.0612246\tvalid_0's l2: 0.0104468\n",
      "[32]\tvalid_0's l1: 0.0610824\tvalid_0's l2: 0.0104347\n",
      "[33]\tvalid_0's l1: 0.060956\tvalid_0's l2: 0.0104241\n",
      "[34]\tvalid_0's l1: 0.0608256\tvalid_0's l2: 0.0104156\n",
      "[35]\tvalid_0's l1: 0.0607313\tvalid_0's l2: 0.0104065\n",
      "[36]\tvalid_0's l1: 0.0606096\tvalid_0's l2: 0.0103953\n",
      "[37]\tvalid_0's l1: 0.060582\tvalid_0's l2: 0.0103945\n",
      "[38]\tvalid_0's l1: 0.0605292\tvalid_0's l2: 0.0103936\n",
      "[39]\tvalid_0's l1: 0.060451\tvalid_0's l2: 0.01039\n",
      "[40]\tvalid_0's l1: 0.0604124\tvalid_0's l2: 0.0103861\n",
      "[41]\tvalid_0's l1: 0.06036\tvalid_0's l2: 0.0103844\n",
      "[42]\tvalid_0's l1: 0.0603214\tvalid_0's l2: 0.0103827\n",
      "[43]\tvalid_0's l1: 0.0602364\tvalid_0's l2: 0.0103756\n",
      "[44]\tvalid_0's l1: 0.0601727\tvalid_0's l2: 0.0103694\n",
      "[45]\tvalid_0's l1: 0.0601032\tvalid_0's l2: 0.0103652\n",
      "[46]\tvalid_0's l1: 0.0600414\tvalid_0's l2: 0.0103609\n",
      "[47]\tvalid_0's l1: 0.0599868\tvalid_0's l2: 0.0103558\n",
      "[48]\tvalid_0's l1: 0.0599757\tvalid_0's l2: 0.0103594\n",
      "[49]\tvalid_0's l1: 0.0599219\tvalid_0's l2: 0.0103552\n",
      "[50]\tvalid_0's l1: 0.0598919\tvalid_0's l2: 0.0103549\n",
      "[51]\tvalid_0's l1: 0.0598375\tvalid_0's l2: 0.0103507\n",
      "[52]\tvalid_0's l1: 0.0598128\tvalid_0's l2: 0.0103492\n",
      "[53]\tvalid_0's l1: 0.0597887\tvalid_0's l2: 0.0103471\n",
      "[54]\tvalid_0's l1: 0.0597407\tvalid_0's l2: 0.0103442\n",
      "[55]\tvalid_0's l1: 0.0596878\tvalid_0's l2: 0.0103423\n",
      "[56]\tvalid_0's l1: 0.0596576\tvalid_0's l2: 0.0103417\n",
      "[57]\tvalid_0's l1: 0.0596007\tvalid_0's l2: 0.0103381\n",
      "[58]\tvalid_0's l1: 0.0595745\tvalid_0's l2: 0.0103382\n",
      "[59]\tvalid_0's l1: 0.0595528\tvalid_0's l2: 0.0103373\n",
      "[60]\tvalid_0's l1: 0.0595101\tvalid_0's l2: 0.0103335\n",
      "[61]\tvalid_0's l1: 0.0594834\tvalid_0's l2: 0.0103311\n",
      "[62]\tvalid_0's l1: 0.0594565\tvalid_0's l2: 0.0103294\n",
      "[63]\tvalid_0's l1: 0.0594305\tvalid_0's l2: 0.0103292\n",
      "[64]\tvalid_0's l1: 0.0594001\tvalid_0's l2: 0.0103273\n",
      "[65]\tvalid_0's l1: 0.0593894\tvalid_0's l2: 0.0103297\n",
      "[66]\tvalid_0's l1: 0.0593734\tvalid_0's l2: 0.0103297\n",
      "[67]\tvalid_0's l1: 0.0593311\tvalid_0's l2: 0.0103286\n",
      "[68]\tvalid_0's l1: 0.0593077\tvalid_0's l2: 0.0103271\n",
      "[69]\tvalid_0's l1: 0.0592885\tvalid_0's l2: 0.0103255\n",
      "[70]\tvalid_0's l1: 0.059259\tvalid_0's l2: 0.0103236\n",
      "[71]\tvalid_0's l1: 0.0592311\tvalid_0's l2: 0.0103221\n",
      "[72]\tvalid_0's l1: 0.0592074\tvalid_0's l2: 0.0103216\n",
      "[73]\tvalid_0's l1: 0.0592021\tvalid_0's l2: 0.0103225\n",
      "[74]\tvalid_0's l1: 0.0591853\tvalid_0's l2: 0.0103203\n",
      "[75]\tvalid_0's l1: 0.059172\tvalid_0's l2: 0.0103206\n",
      "[76]\tvalid_0's l1: 0.0591592\tvalid_0's l2: 0.01032\n",
      "[77]\tvalid_0's l1: 0.0591382\tvalid_0's l2: 0.010319\n",
      "[78]\tvalid_0's l1: 0.0591036\tvalid_0's l2: 0.0103171\n",
      "[79]\tvalid_0's l1: 0.0590918\tvalid_0's l2: 0.0103153\n",
      "[80]\tvalid_0's l1: 0.0590886\tvalid_0's l2: 0.0103179\n",
      "[81]\tvalid_0's l1: 0.0590703\tvalid_0's l2: 0.0103174\n",
      "[82]\tvalid_0's l1: 0.059056\tvalid_0's l2: 0.0103174\n",
      "[83]\tvalid_0's l1: 0.0590339\tvalid_0's l2: 0.0103156\n",
      "[84]\tvalid_0's l1: 0.0590212\tvalid_0's l2: 0.0103143\n",
      "[85]\tvalid_0's l1: 0.0590011\tvalid_0's l2: 0.0103118\n",
      "[86]\tvalid_0's l1: 0.0589883\tvalid_0's l2: 0.0103116\n",
      "[87]\tvalid_0's l1: 0.058983\tvalid_0's l2: 0.0103156\n",
      "[88]\tvalid_0's l1: 0.0589819\tvalid_0's l2: 0.0103159\n",
      "[89]\tvalid_0's l1: 0.0589622\tvalid_0's l2: 0.0103153\n",
      "[90]\tvalid_0's l1: 0.058948\tvalid_0's l2: 0.0103145\n",
      "[91]\tvalid_0's l1: 0.0589391\tvalid_0's l2: 0.0103159\n",
      "[92]\tvalid_0's l1: 0.0589447\tvalid_0's l2: 0.0103175\n",
      "[93]\tvalid_0's l1: 0.058947\tvalid_0's l2: 0.0103186\n",
      "[94]\tvalid_0's l1: 0.0589344\tvalid_0's l2: 0.0103196\n",
      "[95]\tvalid_0's l1: 0.058907\tvalid_0's l2: 0.0103167\n",
      "[96]\tvalid_0's l1: 0.0589085\tvalid_0's l2: 0.0103202\n",
      "[97]\tvalid_0's l1: 0.0588942\tvalid_0's l2: 0.0103178\n",
      "[98]\tvalid_0's l1: 0.0588776\tvalid_0's l2: 0.0103187\n",
      "[99]\tvalid_0's l1: 0.0588633\tvalid_0's l2: 0.0103179\n",
      "[100]\tvalid_0's l1: 0.0588534\tvalid_0's l2: 0.0103173\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 0.0588534\tvalid_0's l2: 0.0103173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['20대 남성 선호도 점수']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['20대 남성 선호도 점수']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "surprised-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "y_train_score_test['20대 남성 선호도 점수'] = y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "municipal-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum += mean_squared_error(y_pred2, np.array(y_train['20대 남성 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "valid-manor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0680334\tvalid_0's l2: 0.0113705\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 0.0655857\tvalid_0's l2: 0.0108737\n",
      "[3]\tvalid_0's l1: 0.0634476\tvalid_0's l2: 0.0104687\n",
      "[4]\tvalid_0's l1: 0.0616008\tvalid_0's l2: 0.0101344\n",
      "[5]\tvalid_0's l1: 0.0601946\tvalid_0's l2: 0.00987935\n",
      "[6]\tvalid_0's l1: 0.0589423\tvalid_0's l2: 0.00966975\n",
      "[7]\tvalid_0's l1: 0.0579736\tvalid_0's l2: 0.0095047\n",
      "[8]\tvalid_0's l1: 0.0568784\tvalid_0's l2: 0.0093462\n",
      "[9]\tvalid_0's l1: 0.0561031\tvalid_0's l2: 0.0092257\n",
      "[10]\tvalid_0's l1: 0.055391\tvalid_0's l2: 0.00912425\n",
      "[11]\tvalid_0's l1: 0.054756\tvalid_0's l2: 0.00904028\n",
      "[12]\tvalid_0's l1: 0.0541211\tvalid_0's l2: 0.00896317\n",
      "[13]\tvalid_0's l1: 0.0536665\tvalid_0's l2: 0.00891426\n",
      "[14]\tvalid_0's l1: 0.0532598\tvalid_0's l2: 0.00886814\n",
      "[15]\tvalid_0's l1: 0.0528617\tvalid_0's l2: 0.00882514\n",
      "[16]\tvalid_0's l1: 0.0525487\tvalid_0's l2: 0.00879288\n",
      "[17]\tvalid_0's l1: 0.0521415\tvalid_0's l2: 0.00875169\n",
      "[18]\tvalid_0's l1: 0.0519777\tvalid_0's l2: 0.00873926\n",
      "[19]\tvalid_0's l1: 0.0516497\tvalid_0's l2: 0.00870883\n",
      "[20]\tvalid_0's l1: 0.0514058\tvalid_0's l2: 0.0086847\n",
      "[21]\tvalid_0's l1: 0.0511827\tvalid_0's l2: 0.0086629\n",
      "[22]\tvalid_0's l1: 0.0509182\tvalid_0's l2: 0.00863954\n",
      "[23]\tvalid_0's l1: 0.0507521\tvalid_0's l2: 0.00863283\n",
      "[24]\tvalid_0's l1: 0.0505625\tvalid_0's l2: 0.00861813\n",
      "[25]\tvalid_0's l1: 0.0504038\tvalid_0's l2: 0.0086057\n",
      "[26]\tvalid_0's l1: 0.0502774\tvalid_0's l2: 0.00859764\n",
      "[27]\tvalid_0's l1: 0.0501833\tvalid_0's l2: 0.00858662\n",
      "[28]\tvalid_0's l1: 0.0501247\tvalid_0's l2: 0.00858115\n",
      "[29]\tvalid_0's l1: 0.0499637\tvalid_0's l2: 0.00856882\n",
      "[30]\tvalid_0's l1: 0.0498036\tvalid_0's l2: 0.00855663\n",
      "[31]\tvalid_0's l1: 0.0497283\tvalid_0's l2: 0.00855083\n",
      "[32]\tvalid_0's l1: 0.049491\tvalid_0's l2: 0.00853261\n",
      "[33]\tvalid_0's l1: 0.0494798\tvalid_0's l2: 0.00853202\n",
      "[34]\tvalid_0's l1: 0.0492825\tvalid_0's l2: 0.00851552\n",
      "[35]\tvalid_0's l1: 0.0491947\tvalid_0's l2: 0.00851215\n",
      "[36]\tvalid_0's l1: 0.0490722\tvalid_0's l2: 0.00850135\n",
      "[37]\tvalid_0's l1: 0.0490509\tvalid_0's l2: 0.00850487\n",
      "[38]\tvalid_0's l1: 0.0489786\tvalid_0's l2: 0.00850543\n",
      "[39]\tvalid_0's l1: 0.0489366\tvalid_0's l2: 0.00850405\n",
      "[40]\tvalid_0's l1: 0.0488487\tvalid_0's l2: 0.00849637\n",
      "[41]\tvalid_0's l1: 0.0487723\tvalid_0's l2: 0.00848642\n",
      "[42]\tvalid_0's l1: 0.0486779\tvalid_0's l2: 0.0084794\n",
      "[43]\tvalid_0's l1: 0.0486646\tvalid_0's l2: 0.00848187\n",
      "[44]\tvalid_0's l1: 0.0485664\tvalid_0's l2: 0.0084731\n",
      "[45]\tvalid_0's l1: 0.0485164\tvalid_0's l2: 0.00846923\n",
      "[46]\tvalid_0's l1: 0.0484776\tvalid_0's l2: 0.00846985\n",
      "[47]\tvalid_0's l1: 0.0484243\tvalid_0's l2: 0.00846879\n",
      "[48]\tvalid_0's l1: 0.0483928\tvalid_0's l2: 0.00846748\n",
      "[49]\tvalid_0's l1: 0.0483537\tvalid_0's l2: 0.00846683\n",
      "[50]\tvalid_0's l1: 0.0483294\tvalid_0's l2: 0.00846947\n",
      "[51]\tvalid_0's l1: 0.0482662\tvalid_0's l2: 0.00846352\n",
      "[52]\tvalid_0's l1: 0.0482438\tvalid_0's l2: 0.0084618\n",
      "[53]\tvalid_0's l1: 0.0482014\tvalid_0's l2: 0.00845754\n",
      "[54]\tvalid_0's l1: 0.0481596\tvalid_0's l2: 0.00845421\n",
      "[55]\tvalid_0's l1: 0.0481214\tvalid_0's l2: 0.00845377\n",
      "[56]\tvalid_0's l1: 0.0480659\tvalid_0's l2: 0.00845021\n",
      "[57]\tvalid_0's l1: 0.048025\tvalid_0's l2: 0.00844969\n",
      "[58]\tvalid_0's l1: 0.0479662\tvalid_0's l2: 0.00844562\n",
      "[59]\tvalid_0's l1: 0.0479516\tvalid_0's l2: 0.00844907\n",
      "[60]\tvalid_0's l1: 0.047928\tvalid_0's l2: 0.00844661\n",
      "[61]\tvalid_0's l1: 0.0478767\tvalid_0's l2: 0.00844274\n",
      "[62]\tvalid_0's l1: 0.0478556\tvalid_0's l2: 0.0084431\n",
      "[63]\tvalid_0's l1: 0.0478325\tvalid_0's l2: 0.00844027\n",
      "[64]\tvalid_0's l1: 0.0478059\tvalid_0's l2: 0.00843943\n",
      "[65]\tvalid_0's l1: 0.0477656\tvalid_0's l2: 0.00843579\n",
      "[66]\tvalid_0's l1: 0.0477192\tvalid_0's l2: 0.00843243\n",
      "[67]\tvalid_0's l1: 0.0476995\tvalid_0's l2: 0.00842949\n",
      "[68]\tvalid_0's l1: 0.0476615\tvalid_0's l2: 0.00842646\n",
      "[69]\tvalid_0's l1: 0.0476367\tvalid_0's l2: 0.00842494\n",
      "[70]\tvalid_0's l1: 0.0475981\tvalid_0's l2: 0.00842227\n",
      "[71]\tvalid_0's l1: 0.0475576\tvalid_0's l2: 0.00841929\n",
      "[72]\tvalid_0's l1: 0.047536\tvalid_0's l2: 0.00841622\n",
      "[73]\tvalid_0's l1: 0.0475248\tvalid_0's l2: 0.00841418\n",
      "[74]\tvalid_0's l1: 0.0474909\tvalid_0's l2: 0.00841209\n",
      "[75]\tvalid_0's l1: 0.0474709\tvalid_0's l2: 0.00840843\n",
      "[76]\tvalid_0's l1: 0.0474544\tvalid_0's l2: 0.00840898\n",
      "[77]\tvalid_0's l1: 0.047428\tvalid_0's l2: 0.00840778\n",
      "[78]\tvalid_0's l1: 0.0474118\tvalid_0's l2: 0.00840811\n",
      "[79]\tvalid_0's l1: 0.0474001\tvalid_0's l2: 0.00841009\n",
      "[80]\tvalid_0's l1: 0.0473827\tvalid_0's l2: 0.00840923\n",
      "[81]\tvalid_0's l1: 0.0473639\tvalid_0's l2: 0.0084086\n",
      "[82]\tvalid_0's l1: 0.0473544\tvalid_0's l2: 0.00840968\n",
      "[83]\tvalid_0's l1: 0.0473278\tvalid_0's l2: 0.00840673\n",
      "[84]\tvalid_0's l1: 0.0473032\tvalid_0's l2: 0.00840464\n",
      "[85]\tvalid_0's l1: 0.0472977\tvalid_0's l2: 0.00840315\n",
      "[86]\tvalid_0's l1: 0.0472873\tvalid_0's l2: 0.00840338\n",
      "[87]\tvalid_0's l1: 0.0472707\tvalid_0's l2: 0.00840245\n",
      "[88]\tvalid_0's l1: 0.0472482\tvalid_0's l2: 0.00839981\n",
      "[89]\tvalid_0's l1: 0.0472179\tvalid_0's l2: 0.00839786\n",
      "[90]\tvalid_0's l1: 0.047204\tvalid_0's l2: 0.0083981\n",
      "[91]\tvalid_0's l1: 0.0471881\tvalid_0's l2: 0.00839786\n",
      "[92]\tvalid_0's l1: 0.047162\tvalid_0's l2: 0.00839519\n",
      "[93]\tvalid_0's l1: 0.047139\tvalid_0's l2: 0.00839586\n",
      "[94]\tvalid_0's l1: 0.0471165\tvalid_0's l2: 0.00839444\n",
      "[95]\tvalid_0's l1: 0.0471008\tvalid_0's l2: 0.0083928\n",
      "[96]\tvalid_0's l1: 0.047088\tvalid_0's l2: 0.00839448\n",
      "[97]\tvalid_0's l1: 0.0470637\tvalid_0's l2: 0.00839289\n",
      "[98]\tvalid_0's l1: 0.047056\tvalid_0's l2: 0.00839343\n",
      "[99]\tvalid_0's l1: 0.047044\tvalid_0's l2: 0.00839336\n",
      "[100]\tvalid_0's l1: 0.0470261\tvalid_0's l2: 0.00839285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 0.0470261\tvalid_0's l2: 0.00839285\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['20대 여성 선호도 점수']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['20대 여성 선호도 점수']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "pregnant-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "y_train_score_test['20대 여성 선호도 점수'] = y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "periodic-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum += mean_squared_error(y_pred2, np.array(y_train['20대 여성 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "interstate-quilt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0711853\tvalid_0's l2: 0.0148332\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 0.0704137\tvalid_0's l2: 0.0146601\n",
      "[3]\tvalid_0's l1: 0.0697862\tvalid_0's l2: 0.0145194\n",
      "[4]\tvalid_0's l1: 0.0691556\tvalid_0's l2: 0.0143973\n",
      "[5]\tvalid_0's l1: 0.0686987\tvalid_0's l2: 0.0142933\n",
      "[6]\tvalid_0's l1: 0.0682346\tvalid_0's l2: 0.0142195\n",
      "[7]\tvalid_0's l1: 0.0678206\tvalid_0's l2: 0.0141391\n",
      "[8]\tvalid_0's l1: 0.0673923\tvalid_0's l2: 0.0140737\n",
      "[9]\tvalid_0's l1: 0.067181\tvalid_0's l2: 0.0140235\n",
      "[10]\tvalid_0's l1: 0.0668504\tvalid_0's l2: 0.0139805\n",
      "[11]\tvalid_0's l1: 0.0667437\tvalid_0's l2: 0.0139522\n",
      "[12]\tvalid_0's l1: 0.0665038\tvalid_0's l2: 0.0139233\n",
      "[13]\tvalid_0's l1: 0.0663105\tvalid_0's l2: 0.0138995\n",
      "[14]\tvalid_0's l1: 0.0662812\tvalid_0's l2: 0.0138903\n",
      "[15]\tvalid_0's l1: 0.0661582\tvalid_0's l2: 0.0138723\n",
      "[16]\tvalid_0's l1: 0.0658997\tvalid_0's l2: 0.013841\n",
      "[17]\tvalid_0's l1: 0.0657983\tvalid_0's l2: 0.0138297\n",
      "[18]\tvalid_0's l1: 0.0657633\tvalid_0's l2: 0.0138199\n",
      "[19]\tvalid_0's l1: 0.065639\tvalid_0's l2: 0.0138031\n",
      "[20]\tvalid_0's l1: 0.0656271\tvalid_0's l2: 0.0138042\n",
      "[21]\tvalid_0's l1: 0.0655749\tvalid_0's l2: 0.0137976\n",
      "[22]\tvalid_0's l1: 0.0655388\tvalid_0's l2: 0.0137933\n",
      "[23]\tvalid_0's l1: 0.065445\tvalid_0's l2: 0.0137823\n",
      "[24]\tvalid_0's l1: 0.065319\tvalid_0's l2: 0.013771\n",
      "[25]\tvalid_0's l1: 0.0653314\tvalid_0's l2: 0.013773\n",
      "[26]\tvalid_0's l1: 0.0652618\tvalid_0's l2: 0.0137675\n",
      "[27]\tvalid_0's l1: 0.0651698\tvalid_0's l2: 0.0137548\n",
      "[28]\tvalid_0's l1: 0.065159\tvalid_0's l2: 0.0137473\n",
      "[29]\tvalid_0's l1: 0.0650989\tvalid_0's l2: 0.0137408\n",
      "[30]\tvalid_0's l1: 0.0651057\tvalid_0's l2: 0.0137491\n",
      "[31]\tvalid_0's l1: 0.0650504\tvalid_0's l2: 0.0137422\n",
      "[32]\tvalid_0's l1: 0.0650378\tvalid_0's l2: 0.0137418\n",
      "[33]\tvalid_0's l1: 0.0649211\tvalid_0's l2: 0.0137282\n",
      "[34]\tvalid_0's l1: 0.0649207\tvalid_0's l2: 0.013729\n",
      "[35]\tvalid_0's l1: 0.0649027\tvalid_0's l2: 0.0137243\n",
      "[36]\tvalid_0's l1: 0.0648952\tvalid_0's l2: 0.0137279\n",
      "[37]\tvalid_0's l1: 0.0648582\tvalid_0's l2: 0.0137275\n",
      "[38]\tvalid_0's l1: 0.0648505\tvalid_0's l2: 0.0137283\n",
      "[39]\tvalid_0's l1: 0.064794\tvalid_0's l2: 0.0137236\n",
      "[40]\tvalid_0's l1: 0.0647198\tvalid_0's l2: 0.0137126\n",
      "[41]\tvalid_0's l1: 0.0647114\tvalid_0's l2: 0.0137091\n",
      "[42]\tvalid_0's l1: 0.0646945\tvalid_0's l2: 0.013705\n",
      "[43]\tvalid_0's l1: 0.064693\tvalid_0's l2: 0.0137082\n",
      "[44]\tvalid_0's l1: 0.0646923\tvalid_0's l2: 0.0137118\n",
      "[45]\tvalid_0's l1: 0.0646773\tvalid_0's l2: 0.0137069\n",
      "[46]\tvalid_0's l1: 0.0646671\tvalid_0's l2: 0.013707\n",
      "[47]\tvalid_0's l1: 0.0646241\tvalid_0's l2: 0.0137032\n",
      "[48]\tvalid_0's l1: 0.0646043\tvalid_0's l2: 0.0137037\n",
      "[49]\tvalid_0's l1: 0.064599\tvalid_0's l2: 0.0137023\n",
      "[50]\tvalid_0's l1: 0.0645431\tvalid_0's l2: 0.0136955\n",
      "[51]\tvalid_0's l1: 0.0645087\tvalid_0's l2: 0.0136897\n",
      "[52]\tvalid_0's l1: 0.0644867\tvalid_0's l2: 0.0136949\n",
      "[53]\tvalid_0's l1: 0.0644768\tvalid_0's l2: 0.0136904\n",
      "[54]\tvalid_0's l1: 0.0644759\tvalid_0's l2: 0.0136919\n",
      "[55]\tvalid_0's l1: 0.0644835\tvalid_0's l2: 0.0137009\n",
      "[56]\tvalid_0's l1: 0.0644203\tvalid_0's l2: 0.0136933\n",
      "[57]\tvalid_0's l1: 0.0644235\tvalid_0's l2: 0.0136932\n",
      "[58]\tvalid_0's l1: 0.0644124\tvalid_0's l2: 0.0136941\n",
      "[59]\tvalid_0's l1: 0.064413\tvalid_0's l2: 0.0136912\n",
      "[60]\tvalid_0's l1: 0.0644011\tvalid_0's l2: 0.013692\n",
      "[61]\tvalid_0's l1: 0.0643596\tvalid_0's l2: 0.0136894\n",
      "[62]\tvalid_0's l1: 0.0643358\tvalid_0's l2: 0.013687\n",
      "[63]\tvalid_0's l1: 0.0642917\tvalid_0's l2: 0.0136848\n",
      "[64]\tvalid_0's l1: 0.0642944\tvalid_0's l2: 0.0136822\n",
      "[65]\tvalid_0's l1: 0.0642927\tvalid_0's l2: 0.0136827\n",
      "[66]\tvalid_0's l1: 0.064285\tvalid_0's l2: 0.0136817\n",
      "[67]\tvalid_0's l1: 0.0642603\tvalid_0's l2: 0.0136822\n",
      "[68]\tvalid_0's l1: 0.0642478\tvalid_0's l2: 0.0136837\n",
      "[69]\tvalid_0's l1: 0.0642375\tvalid_0's l2: 0.0136845\n",
      "[70]\tvalid_0's l1: 0.0642455\tvalid_0's l2: 0.0136898\n",
      "[71]\tvalid_0's l1: 0.0642437\tvalid_0's l2: 0.0136911\n",
      "[72]\tvalid_0's l1: 0.0642591\tvalid_0's l2: 0.0136955\n",
      "[73]\tvalid_0's l1: 0.0642298\tvalid_0's l2: 0.0136941\n",
      "[74]\tvalid_0's l1: 0.0642099\tvalid_0's l2: 0.0136951\n",
      "[75]\tvalid_0's l1: 0.0641908\tvalid_0's l2: 0.0136921\n",
      "[76]\tvalid_0's l1: 0.0641993\tvalid_0's l2: 0.0136993\n",
      "[77]\tvalid_0's l1: 0.0642013\tvalid_0's l2: 0.0137042\n",
      "[78]\tvalid_0's l1: 0.0642002\tvalid_0's l2: 0.0137084\n",
      "[79]\tvalid_0's l1: 0.0641942\tvalid_0's l2: 0.0137101\n",
      "[80]\tvalid_0's l1: 0.0641894\tvalid_0's l2: 0.0137135\n",
      "[81]\tvalid_0's l1: 0.0641729\tvalid_0's l2: 0.0137101\n",
      "[82]\tvalid_0's l1: 0.0641707\tvalid_0's l2: 0.0137136\n",
      "[83]\tvalid_0's l1: 0.0641402\tvalid_0's l2: 0.013712\n",
      "[84]\tvalid_0's l1: 0.0641318\tvalid_0's l2: 0.0137096\n",
      "[85]\tvalid_0's l1: 0.0641412\tvalid_0's l2: 0.0137126\n",
      "[86]\tvalid_0's l1: 0.0641492\tvalid_0's l2: 0.013718\n",
      "[87]\tvalid_0's l1: 0.0641225\tvalid_0's l2: 0.013715\n",
      "[88]\tvalid_0's l1: 0.0641073\tvalid_0's l2: 0.0137122\n",
      "[89]\tvalid_0's l1: 0.0641149\tvalid_0's l2: 0.0137162\n",
      "[90]\tvalid_0's l1: 0.0641177\tvalid_0's l2: 0.0137206\n",
      "[91]\tvalid_0's l1: 0.0641124\tvalid_0's l2: 0.0137207\n",
      "[92]\tvalid_0's l1: 0.0641241\tvalid_0's l2: 0.0137252\n",
      "[93]\tvalid_0's l1: 0.0641065\tvalid_0's l2: 0.0137245\n",
      "[94]\tvalid_0's l1: 0.0640978\tvalid_0's l2: 0.0137244\n",
      "[95]\tvalid_0's l1: 0.0641037\tvalid_0's l2: 0.0137264\n",
      "[96]\tvalid_0's l1: 0.0640935\tvalid_0's l2: 0.0137274\n",
      "[97]\tvalid_0's l1: 0.064099\tvalid_0's l2: 0.0137313\n",
      "[98]\tvalid_0's l1: 0.064077\tvalid_0's l2: 0.0137285\n",
      "[99]\tvalid_0's l1: 0.0640775\tvalid_0's l2: 0.0137295\n",
      "[100]\tvalid_0's l1: 0.0640788\tvalid_0's l2: 0.0137289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's l1: 0.064077\tvalid_0's l2: 0.0137285\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['30대 남성 선호도 점수']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['30대 남성 선호도 점수']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "y_train_score_test['30대 남성 선호도 점수'] = y_pred2\n",
    "\n",
    "sum += mean_squared_error(y_pred2, np.array(y_train['30대 남성 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "spanish-disney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0621383\tvalid_0's l2: 0.0148137\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 0.0614749\tvalid_0's l2: 0.0146543\n",
      "[3]\tvalid_0's l1: 0.0608603\tvalid_0's l2: 0.0145087\n",
      "[4]\tvalid_0's l1: 0.0602512\tvalid_0's l2: 0.0143811\n",
      "[5]\tvalid_0's l1: 0.0597126\tvalid_0's l2: 0.0142845\n",
      "[6]\tvalid_0's l1: 0.0593101\tvalid_0's l2: 0.0141908\n",
      "[7]\tvalid_0's l1: 0.0588695\tvalid_0's l2: 0.0141232\n",
      "[8]\tvalid_0's l1: 0.0586438\tvalid_0's l2: 0.0140695\n",
      "[9]\tvalid_0's l1: 0.0583319\tvalid_0's l2: 0.0140205\n",
      "[10]\tvalid_0's l1: 0.0580236\tvalid_0's l2: 0.0139736\n",
      "[11]\tvalid_0's l1: 0.0579681\tvalid_0's l2: 0.0139551\n",
      "[12]\tvalid_0's l1: 0.0575916\tvalid_0's l2: 0.0139128\n",
      "[13]\tvalid_0's l1: 0.0574502\tvalid_0's l2: 0.0138834\n",
      "[14]\tvalid_0's l1: 0.0573442\tvalid_0's l2: 0.0138759\n",
      "[15]\tvalid_0's l1: 0.0570314\tvalid_0's l2: 0.0138464\n",
      "[16]\tvalid_0's l1: 0.0568922\tvalid_0's l2: 0.0138156\n",
      "[17]\tvalid_0's l1: 0.0567743\tvalid_0's l2: 0.0138044\n",
      "[18]\tvalid_0's l1: 0.0567062\tvalid_0's l2: 0.0137958\n",
      "[19]\tvalid_0's l1: 0.0564748\tvalid_0's l2: 0.0137778\n",
      "[20]\tvalid_0's l1: 0.0564735\tvalid_0's l2: 0.0137677\n",
      "[21]\tvalid_0's l1: 0.056241\tvalid_0's l2: 0.0137447\n",
      "[22]\tvalid_0's l1: 0.0561008\tvalid_0's l2: 0.0137229\n",
      "[23]\tvalid_0's l1: 0.0560804\tvalid_0's l2: 0.0137219\n",
      "[24]\tvalid_0's l1: 0.0559042\tvalid_0's l2: 0.013711\n",
      "[25]\tvalid_0's l1: 0.0558271\tvalid_0's l2: 0.013703\n",
      "[26]\tvalid_0's l1: 0.0556781\tvalid_0's l2: 0.0136854\n",
      "[27]\tvalid_0's l1: 0.0556711\tvalid_0's l2: 0.013679\n",
      "[28]\tvalid_0's l1: 0.0556199\tvalid_0's l2: 0.0136658\n",
      "[29]\tvalid_0's l1: 0.0554451\tvalid_0's l2: 0.013651\n",
      "[30]\tvalid_0's l1: 0.0553228\tvalid_0's l2: 0.013638\n",
      "[31]\tvalid_0's l1: 0.055295\tvalid_0's l2: 0.0136302\n",
      "[32]\tvalid_0's l1: 0.0552403\tvalid_0's l2: 0.0136277\n",
      "[33]\tvalid_0's l1: 0.0551675\tvalid_0's l2: 0.0136264\n",
      "[34]\tvalid_0's l1: 0.0551037\tvalid_0's l2: 0.0136258\n",
      "[35]\tvalid_0's l1: 0.0551171\tvalid_0's l2: 0.0136248\n",
      "[36]\tvalid_0's l1: 0.0550325\tvalid_0's l2: 0.0136145\n",
      "[37]\tvalid_0's l1: 0.0549793\tvalid_0's l2: 0.013608\n",
      "[38]\tvalid_0's l1: 0.054989\tvalid_0's l2: 0.0136134\n",
      "[39]\tvalid_0's l1: 0.0549665\tvalid_0's l2: 0.013608\n",
      "[40]\tvalid_0's l1: 0.0548486\tvalid_0's l2: 0.0136089\n",
      "[41]\tvalid_0's l1: 0.0547841\tvalid_0's l2: 0.0136024\n",
      "[42]\tvalid_0's l1: 0.0546806\tvalid_0's l2: 0.0135907\n",
      "[43]\tvalid_0's l1: 0.0546567\tvalid_0's l2: 0.0135918\n",
      "[44]\tvalid_0's l1: 0.0546182\tvalid_0's l2: 0.0135882\n",
      "[45]\tvalid_0's l1: 0.0545991\tvalid_0's l2: 0.0135832\n",
      "[46]\tvalid_0's l1: 0.0545829\tvalid_0's l2: 0.013583\n",
      "[47]\tvalid_0's l1: 0.0545018\tvalid_0's l2: 0.0135762\n",
      "[48]\tvalid_0's l1: 0.0544607\tvalid_0's l2: 0.0135709\n",
      "[49]\tvalid_0's l1: 0.0543633\tvalid_0's l2: 0.0135658\n",
      "[50]\tvalid_0's l1: 0.054364\tvalid_0's l2: 0.0135629\n",
      "[51]\tvalid_0's l1: 0.0543198\tvalid_0's l2: 0.0135609\n",
      "[52]\tvalid_0's l1: 0.0542932\tvalid_0's l2: 0.0135588\n",
      "[53]\tvalid_0's l1: 0.0543031\tvalid_0's l2: 0.0135582\n",
      "[54]\tvalid_0's l1: 0.0542878\tvalid_0's l2: 0.0135521\n",
      "[55]\tvalid_0's l1: 0.0542687\tvalid_0's l2: 0.0135453\n",
      "[56]\tvalid_0's l1: 0.0541893\tvalid_0's l2: 0.013539\n",
      "[57]\tvalid_0's l1: 0.0541763\tvalid_0's l2: 0.0135384\n",
      "[58]\tvalid_0's l1: 0.0541673\tvalid_0's l2: 0.0135421\n",
      "[59]\tvalid_0's l1: 0.0540564\tvalid_0's l2: 0.0135357\n",
      "[60]\tvalid_0's l1: 0.0540253\tvalid_0's l2: 0.0135311\n",
      "[61]\tvalid_0's l1: 0.053983\tvalid_0's l2: 0.0135268\n",
      "[62]\tvalid_0's l1: 0.0539644\tvalid_0's l2: 0.0135233\n",
      "[63]\tvalid_0's l1: 0.0539236\tvalid_0's l2: 0.013519\n",
      "[64]\tvalid_0's l1: 0.0538983\tvalid_0's l2: 0.0135188\n",
      "[65]\tvalid_0's l1: 0.0539026\tvalid_0's l2: 0.0135208\n",
      "[66]\tvalid_0's l1: 0.0538704\tvalid_0's l2: 0.0135156\n",
      "[67]\tvalid_0's l1: 0.0538496\tvalid_0's l2: 0.0135121\n",
      "[68]\tvalid_0's l1: 0.0538311\tvalid_0's l2: 0.013508\n",
      "[69]\tvalid_0's l1: 0.0538145\tvalid_0's l2: 0.0135056\n",
      "[70]\tvalid_0's l1: 0.0537875\tvalid_0's l2: 0.0135093\n",
      "[71]\tvalid_0's l1: 0.0537961\tvalid_0's l2: 0.013515\n",
      "[72]\tvalid_0's l1: 0.0537714\tvalid_0's l2: 0.0135136\n",
      "[73]\tvalid_0's l1: 0.0537266\tvalid_0's l2: 0.0135086\n",
      "[74]\tvalid_0's l1: 0.0537309\tvalid_0's l2: 0.0135159\n",
      "[75]\tvalid_0's l1: 0.0537239\tvalid_0's l2: 0.0135124\n",
      "[76]\tvalid_0's l1: 0.0537084\tvalid_0's l2: 0.0135128\n",
      "[77]\tvalid_0's l1: 0.0536913\tvalid_0's l2: 0.013513\n",
      "[78]\tvalid_0's l1: 0.0536918\tvalid_0's l2: 0.0135172\n",
      "[79]\tvalid_0's l1: 0.0536392\tvalid_0's l2: 0.0135136\n",
      "[80]\tvalid_0's l1: 0.0536134\tvalid_0's l2: 0.0135122\n",
      "[81]\tvalid_0's l1: 0.0536126\tvalid_0's l2: 0.0135128\n",
      "[82]\tvalid_0's l1: 0.0536052\tvalid_0's l2: 0.0135135\n",
      "[83]\tvalid_0's l1: 0.0535895\tvalid_0's l2: 0.0135121\n",
      "[84]\tvalid_0's l1: 0.0535879\tvalid_0's l2: 0.0135186\n",
      "[85]\tvalid_0's l1: 0.0535912\tvalid_0's l2: 0.0135227\n",
      "[86]\tvalid_0's l1: 0.0535974\tvalid_0's l2: 0.0135274\n",
      "[87]\tvalid_0's l1: 0.0535738\tvalid_0's l2: 0.0135248\n",
      "[88]\tvalid_0's l1: 0.0535235\tvalid_0's l2: 0.0135236\n",
      "[89]\tvalid_0's l1: 0.0535032\tvalid_0's l2: 0.0135186\n",
      "[90]\tvalid_0's l1: 0.0534922\tvalid_0's l2: 0.0135163\n",
      "[91]\tvalid_0's l1: 0.0534928\tvalid_0's l2: 0.0135117\n",
      "[92]\tvalid_0's l1: 0.0534916\tvalid_0's l2: 0.0135149\n",
      "[93]\tvalid_0's l1: 0.0534903\tvalid_0's l2: 0.0135175\n",
      "[94]\tvalid_0's l1: 0.0534842\tvalid_0's l2: 0.0135202\n",
      "[95]\tvalid_0's l1: 0.0534754\tvalid_0's l2: 0.0135192\n",
      "[96]\tvalid_0's l1: 0.0534477\tvalid_0's l2: 0.0135075\n",
      "[97]\tvalid_0's l1: 0.0534388\tvalid_0's l2: 0.0135066\n",
      "[98]\tvalid_0's l1: 0.0534341\tvalid_0's l2: 0.0135086\n",
      "[99]\tvalid_0's l1: 0.0534225\tvalid_0's l2: 0.0135038\n",
      "[100]\tvalid_0's l1: 0.053411\tvalid_0's l2: 0.0135038\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 0.053411\tvalid_0's l2: 0.0135038\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['30대 여성 선호도 점수']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['30대 여성 선호도 점수']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "y_train_score_test['30대 여성 선호도 점수'] = y_pred2\n",
    "\n",
    "sum += mean_squared_error(y_pred2, np.array(y_train['30대 여성 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "scheduled-nation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0717974\tvalid_0's l2: 0.016227\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 0.0716177\tvalid_0's l2: 0.016131\n",
      "[3]\tvalid_0's l1: 0.0715499\tvalid_0's l2: 0.0160614\n",
      "[4]\tvalid_0's l1: 0.0713788\tvalid_0's l2: 0.0160068\n",
      "[5]\tvalid_0's l1: 0.0711757\tvalid_0's l2: 0.0159364\n",
      "[6]\tvalid_0's l1: 0.0709409\tvalid_0's l2: 0.0158891\n",
      "[7]\tvalid_0's l1: 0.0709462\tvalid_0's l2: 0.0158583\n",
      "[8]\tvalid_0's l1: 0.0707467\tvalid_0's l2: 0.0158241\n",
      "[9]\tvalid_0's l1: 0.0706634\tvalid_0's l2: 0.0157953\n",
      "[10]\tvalid_0's l1: 0.0704638\tvalid_0's l2: 0.0157682\n",
      "[11]\tvalid_0's l1: 0.0704198\tvalid_0's l2: 0.0157517\n",
      "[12]\tvalid_0's l1: 0.070172\tvalid_0's l2: 0.0157196\n",
      "[13]\tvalid_0's l1: 0.0701192\tvalid_0's l2: 0.0157068\n",
      "[14]\tvalid_0's l1: 0.0701043\tvalid_0's l2: 0.0157009\n",
      "[15]\tvalid_0's l1: 0.0700652\tvalid_0's l2: 0.0156821\n",
      "[16]\tvalid_0's l1: 0.0698629\tvalid_0's l2: 0.0156632\n",
      "[17]\tvalid_0's l1: 0.0698408\tvalid_0's l2: 0.0156607\n",
      "[18]\tvalid_0's l1: 0.0698384\tvalid_0's l2: 0.015666\n",
      "[19]\tvalid_0's l1: 0.0698342\tvalid_0's l2: 0.0156544\n",
      "[20]\tvalid_0's l1: 0.0697595\tvalid_0's l2: 0.015639\n",
      "[21]\tvalid_0's l1: 0.0695764\tvalid_0's l2: 0.0156207\n",
      "[22]\tvalid_0's l1: 0.06959\tvalid_0's l2: 0.0156256\n",
      "[23]\tvalid_0's l1: 0.0696017\tvalid_0's l2: 0.0156327\n",
      "[24]\tvalid_0's l1: 0.0695466\tvalid_0's l2: 0.015618\n",
      "[25]\tvalid_0's l1: 0.0694006\tvalid_0's l2: 0.0156024\n",
      "[26]\tvalid_0's l1: 0.0693882\tvalid_0's l2: 0.0155964\n",
      "[27]\tvalid_0's l1: 0.0693818\tvalid_0's l2: 0.0155988\n",
      "[28]\tvalid_0's l1: 0.0693975\tvalid_0's l2: 0.0156055\n",
      "[29]\tvalid_0's l1: 0.0693836\tvalid_0's l2: 0.0156032\n",
      "[30]\tvalid_0's l1: 0.0692652\tvalid_0's l2: 0.015593\n",
      "[31]\tvalid_0's l1: 0.0692331\tvalid_0's l2: 0.0155838\n",
      "[32]\tvalid_0's l1: 0.0692343\tvalid_0's l2: 0.0155858\n",
      "[33]\tvalid_0's l1: 0.0692275\tvalid_0's l2: 0.0155839\n",
      "[34]\tvalid_0's l1: 0.0692101\tvalid_0's l2: 0.0155811\n",
      "[35]\tvalid_0's l1: 0.0691972\tvalid_0's l2: 0.0155784\n",
      "[36]\tvalid_0's l1: 0.0691832\tvalid_0's l2: 0.0155738\n",
      "[37]\tvalid_0's l1: 0.069183\tvalid_0's l2: 0.0155714\n",
      "[38]\tvalid_0's l1: 0.0691637\tvalid_0's l2: 0.0155765\n",
      "[39]\tvalid_0's l1: 0.0690763\tvalid_0's l2: 0.0155698\n",
      "[40]\tvalid_0's l1: 0.0690812\tvalid_0's l2: 0.0155793\n",
      "[41]\tvalid_0's l1: 0.069061\tvalid_0's l2: 0.0155778\n",
      "[42]\tvalid_0's l1: 0.0690747\tvalid_0's l2: 0.0155819\n",
      "[43]\tvalid_0's l1: 0.0690644\tvalid_0's l2: 0.0155822\n",
      "[44]\tvalid_0's l1: 0.0690654\tvalid_0's l2: 0.0155839\n",
      "[45]\tvalid_0's l1: 0.0689892\tvalid_0's l2: 0.015574\n",
      "[46]\tvalid_0's l1: 0.0689815\tvalid_0's l2: 0.0155771\n",
      "[47]\tvalid_0's l1: 0.0689798\tvalid_0's l2: 0.0155754\n",
      "[48]\tvalid_0's l1: 0.0689793\tvalid_0's l2: 0.0155787\n",
      "[49]\tvalid_0's l1: 0.0689683\tvalid_0's l2: 0.0155791\n",
      "[50]\tvalid_0's l1: 0.0689732\tvalid_0's l2: 0.0155801\n",
      "[51]\tvalid_0's l1: 0.0689705\tvalid_0's l2: 0.0155834\n",
      "[52]\tvalid_0's l1: 0.0689619\tvalid_0's l2: 0.0155847\n",
      "[53]\tvalid_0's l1: 0.0689486\tvalid_0's l2: 0.015583\n",
      "[54]\tvalid_0's l1: 0.0688745\tvalid_0's l2: 0.0155728\n",
      "[55]\tvalid_0's l1: 0.0688685\tvalid_0's l2: 0.0155734\n",
      "[56]\tvalid_0's l1: 0.068871\tvalid_0's l2: 0.0155708\n",
      "[57]\tvalid_0's l1: 0.0688802\tvalid_0's l2: 0.0155725\n",
      "[58]\tvalid_0's l1: 0.0688842\tvalid_0's l2: 0.0155736\n",
      "[59]\tvalid_0's l1: 0.0688823\tvalid_0's l2: 0.0155716\n",
      "[60]\tvalid_0's l1: 0.0688677\tvalid_0's l2: 0.0155706\n",
      "[61]\tvalid_0's l1: 0.0688606\tvalid_0's l2: 0.0155694\n",
      "[62]\tvalid_0's l1: 0.0688764\tvalid_0's l2: 0.0155756\n",
      "[63]\tvalid_0's l1: 0.0688692\tvalid_0's l2: 0.0155739\n",
      "[64]\tvalid_0's l1: 0.0688719\tvalid_0's l2: 0.0155761\n",
      "[65]\tvalid_0's l1: 0.0688266\tvalid_0's l2: 0.015574\n",
      "[66]\tvalid_0's l1: 0.0688443\tvalid_0's l2: 0.0155789\n",
      "[67]\tvalid_0's l1: 0.0688468\tvalid_0's l2: 0.0155864\n",
      "[68]\tvalid_0's l1: 0.0688437\tvalid_0's l2: 0.0155854\n",
      "[69]\tvalid_0's l1: 0.0688549\tvalid_0's l2: 0.0155875\n",
      "[70]\tvalid_0's l1: 0.0688576\tvalid_0's l2: 0.0155916\n",
      "[71]\tvalid_0's l1: 0.068858\tvalid_0's l2: 0.0155895\n",
      "[72]\tvalid_0's l1: 0.0688469\tvalid_0's l2: 0.0155883\n",
      "[73]\tvalid_0's l1: 0.0688412\tvalid_0's l2: 0.0155857\n",
      "[74]\tvalid_0's l1: 0.0688544\tvalid_0's l2: 0.015592\n",
      "[75]\tvalid_0's l1: 0.0688493\tvalid_0's l2: 0.0155921\n",
      "[76]\tvalid_0's l1: 0.0688089\tvalid_0's l2: 0.015586\n",
      "[77]\tvalid_0's l1: 0.0688092\tvalid_0's l2: 0.0155803\n",
      "[78]\tvalid_0's l1: 0.0688099\tvalid_0's l2: 0.015582\n",
      "[79]\tvalid_0's l1: 0.0688148\tvalid_0's l2: 0.0155856\n",
      "[80]\tvalid_0's l1: 0.0687854\tvalid_0's l2: 0.015585\n",
      "[81]\tvalid_0's l1: 0.0687871\tvalid_0's l2: 0.0155845\n",
      "[82]\tvalid_0's l1: 0.0688055\tvalid_0's l2: 0.015587\n",
      "[83]\tvalid_0's l1: 0.0688015\tvalid_0's l2: 0.0155869\n",
      "[84]\tvalid_0's l1: 0.0688034\tvalid_0's l2: 0.015595\n",
      "[85]\tvalid_0's l1: 0.0688029\tvalid_0's l2: 0.0155966\n",
      "[86]\tvalid_0's l1: 0.0688022\tvalid_0's l2: 0.0155949\n",
      "[87]\tvalid_0's l1: 0.0688008\tvalid_0's l2: 0.0155978\n",
      "[88]\tvalid_0's l1: 0.0688009\tvalid_0's l2: 0.0155992\n",
      "[89]\tvalid_0's l1: 0.0688021\tvalid_0's l2: 0.0156009\n",
      "[90]\tvalid_0's l1: 0.0688207\tvalid_0's l2: 0.0156045\n",
      "[91]\tvalid_0's l1: 0.0688248\tvalid_0's l2: 0.0156077\n",
      "[92]\tvalid_0's l1: 0.0688303\tvalid_0's l2: 0.0156085\n",
      "[93]\tvalid_0's l1: 0.068838\tvalid_0's l2: 0.0156137\n",
      "[94]\tvalid_0's l1: 0.0688398\tvalid_0's l2: 0.015615\n",
      "[95]\tvalid_0's l1: 0.0688322\tvalid_0's l2: 0.0156123\n",
      "[96]\tvalid_0's l1: 0.0688324\tvalid_0's l2: 0.015614\n",
      "[97]\tvalid_0's l1: 0.0688493\tvalid_0's l2: 0.0156283\n",
      "[98]\tvalid_0's l1: 0.0688501\tvalid_0's l2: 0.0156288\n",
      "[99]\tvalid_0's l1: 0.068843\tvalid_0's l2: 0.015628\n",
      "[100]\tvalid_0's l1: 0.0688522\tvalid_0's l2: 0.0156323\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\tvalid_0's l1: 0.0687854\tvalid_0's l2: 0.015585\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['40대 남성 선호도 점수']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['40대 남성 선호도 점수']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "y_train_score_test['40대 남성 선호도 점수'] = y_pred2\n",
    "\n",
    "sum += mean_squared_error(y_pred2, np.array(y_train['40대 남성 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "material-niger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0568591\tvalid_0's l2: 0.0124428\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 0.0564794\tvalid_0's l2: 0.0123507\n",
      "[3]\tvalid_0's l1: 0.0561828\tvalid_0's l2: 0.012281\n",
      "[4]\tvalid_0's l1: 0.0558845\tvalid_0's l2: 0.0122184\n",
      "[5]\tvalid_0's l1: 0.055654\tvalid_0's l2: 0.0121655\n",
      "[6]\tvalid_0's l1: 0.0553214\tvalid_0's l2: 0.0121092\n",
      "[7]\tvalid_0's l1: 0.0551943\tvalid_0's l2: 0.0120845\n",
      "[8]\tvalid_0's l1: 0.0549058\tvalid_0's l2: 0.0120495\n",
      "[9]\tvalid_0's l1: 0.0548356\tvalid_0's l2: 0.0120359\n",
      "[10]\tvalid_0's l1: 0.0545965\tvalid_0's l2: 0.0120152\n",
      "[11]\tvalid_0's l1: 0.0544961\tvalid_0's l2: 0.0120013\n",
      "[12]\tvalid_0's l1: 0.0544776\tvalid_0's l2: 0.0120025\n",
      "[13]\tvalid_0's l1: 0.054277\tvalid_0's l2: 0.0119834\n",
      "[14]\tvalid_0's l1: 0.054085\tvalid_0's l2: 0.0119653\n",
      "[15]\tvalid_0's l1: 0.0541184\tvalid_0's l2: 0.0119827\n",
      "[16]\tvalid_0's l1: 0.0538944\tvalid_0's l2: 0.0119572\n",
      "[17]\tvalid_0's l1: 0.0537986\tvalid_0's l2: 0.011953\n",
      "[18]\tvalid_0's l1: 0.0538125\tvalid_0's l2: 0.0119602\n",
      "[19]\tvalid_0's l1: 0.0536382\tvalid_0's l2: 0.0119451\n",
      "[20]\tvalid_0's l1: 0.0535099\tvalid_0's l2: 0.0119361\n",
      "[21]\tvalid_0's l1: 0.0535192\tvalid_0's l2: 0.0119438\n",
      "[22]\tvalid_0's l1: 0.0534193\tvalid_0's l2: 0.0119324\n",
      "[23]\tvalid_0's l1: 0.0534017\tvalid_0's l2: 0.0119239\n",
      "[24]\tvalid_0's l1: 0.0533087\tvalid_0's l2: 0.0119182\n",
      "[25]\tvalid_0's l1: 0.0533182\tvalid_0's l2: 0.0119257\n",
      "[26]\tvalid_0's l1: 0.0532973\tvalid_0's l2: 0.0119215\n",
      "[27]\tvalid_0's l1: 0.0532139\tvalid_0's l2: 0.0119131\n",
      "[28]\tvalid_0's l1: 0.0532233\tvalid_0's l2: 0.0119198\n",
      "[29]\tvalid_0's l1: 0.053135\tvalid_0's l2: 0.0119098\n",
      "[30]\tvalid_0's l1: 0.0531148\tvalid_0's l2: 0.011912\n",
      "[31]\tvalid_0's l1: 0.0530772\tvalid_0's l2: 0.0119115\n",
      "[32]\tvalid_0's l1: 0.0530695\tvalid_0's l2: 0.0119092\n",
      "[33]\tvalid_0's l1: 0.0530742\tvalid_0's l2: 0.0119157\n",
      "[34]\tvalid_0's l1: 0.0530349\tvalid_0's l2: 0.0119091\n",
      "[35]\tvalid_0's l1: 0.0530318\tvalid_0's l2: 0.0119008\n",
      "[36]\tvalid_0's l1: 0.0529617\tvalid_0's l2: 0.0118936\n",
      "[37]\tvalid_0's l1: 0.0528684\tvalid_0's l2: 0.0118869\n",
      "[38]\tvalid_0's l1: 0.0528718\tvalid_0's l2: 0.0118859\n",
      "[39]\tvalid_0's l1: 0.0528766\tvalid_0's l2: 0.0118943\n",
      "[40]\tvalid_0's l1: 0.0528284\tvalid_0's l2: 0.0118906\n",
      "[41]\tvalid_0's l1: 0.0528368\tvalid_0's l2: 0.0118936\n",
      "[42]\tvalid_0's l1: 0.052797\tvalid_0's l2: 0.0118908\n",
      "[43]\tvalid_0's l1: 0.0527729\tvalid_0's l2: 0.0118882\n",
      "[44]\tvalid_0's l1: 0.0526973\tvalid_0's l2: 0.0118814\n",
      "[45]\tvalid_0's l1: 0.0526965\tvalid_0's l2: 0.0118851\n",
      "[46]\tvalid_0's l1: 0.052684\tvalid_0's l2: 0.011875\n",
      "[47]\tvalid_0's l1: 0.0526849\tvalid_0's l2: 0.0118799\n",
      "[48]\tvalid_0's l1: 0.0526403\tvalid_0's l2: 0.0118769\n",
      "[49]\tvalid_0's l1: 0.0526507\tvalid_0's l2: 0.0118905\n",
      "[50]\tvalid_0's l1: 0.0526321\tvalid_0's l2: 0.0118883\n",
      "[51]\tvalid_0's l1: 0.0526334\tvalid_0's l2: 0.0118885\n",
      "[52]\tvalid_0's l1: 0.0526167\tvalid_0's l2: 0.0118907\n",
      "[53]\tvalid_0's l1: 0.0525685\tvalid_0's l2: 0.0118911\n",
      "[54]\tvalid_0's l1: 0.0525765\tvalid_0's l2: 0.0118956\n",
      "[55]\tvalid_0's l1: 0.0525499\tvalid_0's l2: 0.011895\n",
      "[56]\tvalid_0's l1: 0.052546\tvalid_0's l2: 0.0118922\n",
      "[57]\tvalid_0's l1: 0.0525368\tvalid_0's l2: 0.0118901\n",
      "[58]\tvalid_0's l1: 0.0525041\tvalid_0's l2: 0.0118881\n",
      "[59]\tvalid_0's l1: 0.0524894\tvalid_0's l2: 0.0118922\n",
      "[60]\tvalid_0's l1: 0.0524956\tvalid_0's l2: 0.0118959\n",
      "[61]\tvalid_0's l1: 0.0524696\tvalid_0's l2: 0.0118944\n",
      "[62]\tvalid_0's l1: 0.0524558\tvalid_0's l2: 0.0118932\n",
      "[63]\tvalid_0's l1: 0.0524377\tvalid_0's l2: 0.0118923\n",
      "[64]\tvalid_0's l1: 0.0524211\tvalid_0's l2: 0.011892\n",
      "[65]\tvalid_0's l1: 0.0524267\tvalid_0's l2: 0.011894\n",
      "[66]\tvalid_0's l1: 0.0524332\tvalid_0's l2: 0.0119093\n",
      "[67]\tvalid_0's l1: 0.0524364\tvalid_0's l2: 0.0119153\n",
      "[68]\tvalid_0's l1: 0.0524222\tvalid_0's l2: 0.011915\n",
      "[69]\tvalid_0's l1: 0.052415\tvalid_0's l2: 0.0119187\n",
      "[70]\tvalid_0's l1: 0.0523926\tvalid_0's l2: 0.0119231\n",
      "[71]\tvalid_0's l1: 0.0523775\tvalid_0's l2: 0.0119223\n",
      "[72]\tvalid_0's l1: 0.0523717\tvalid_0's l2: 0.0119227\n",
      "[73]\tvalid_0's l1: 0.0523598\tvalid_0's l2: 0.0119219\n",
      "[74]\tvalid_0's l1: 0.0523584\tvalid_0's l2: 0.0119212\n",
      "[75]\tvalid_0's l1: 0.0523637\tvalid_0's l2: 0.0119246\n",
      "[76]\tvalid_0's l1: 0.0523541\tvalid_0's l2: 0.0119241\n",
      "[77]\tvalid_0's l1: 0.0523692\tvalid_0's l2: 0.0119275\n",
      "[78]\tvalid_0's l1: 0.0523771\tvalid_0's l2: 0.011929\n",
      "[79]\tvalid_0's l1: 0.0523576\tvalid_0's l2: 0.0119266\n",
      "[80]\tvalid_0's l1: 0.0523379\tvalid_0's l2: 0.011926\n",
      "[81]\tvalid_0's l1: 0.0523195\tvalid_0's l2: 0.0119249\n",
      "[82]\tvalid_0's l1: 0.052309\tvalid_0's l2: 0.0119268\n",
      "[83]\tvalid_0's l1: 0.0523036\tvalid_0's l2: 0.0119254\n",
      "[84]\tvalid_0's l1: 0.0523048\tvalid_0's l2: 0.0119279\n",
      "[85]\tvalid_0's l1: 0.0523104\tvalid_0's l2: 0.0119308\n",
      "[86]\tvalid_0's l1: 0.0523084\tvalid_0's l2: 0.0119327\n",
      "[87]\tvalid_0's l1: 0.0523056\tvalid_0's l2: 0.0119331\n",
      "[88]\tvalid_0's l1: 0.0523023\tvalid_0's l2: 0.0119348\n",
      "[89]\tvalid_0's l1: 0.0522966\tvalid_0's l2: 0.0119362\n",
      "[90]\tvalid_0's l1: 0.0523014\tvalid_0's l2: 0.0119363\n",
      "[91]\tvalid_0's l1: 0.0522991\tvalid_0's l2: 0.0119367\n",
      "[92]\tvalid_0's l1: 0.0522962\tvalid_0's l2: 0.0119341\n",
      "[93]\tvalid_0's l1: 0.0522899\tvalid_0's l2: 0.0119338\n",
      "[94]\tvalid_0's l1: 0.0522754\tvalid_0's l2: 0.011932\n",
      "[95]\tvalid_0's l1: 0.052279\tvalid_0's l2: 0.0119331\n",
      "[96]\tvalid_0's l1: 0.0522782\tvalid_0's l2: 0.0119326\n",
      "[97]\tvalid_0's l1: 0.0522856\tvalid_0's l2: 0.011932\n",
      "[98]\tvalid_0's l1: 0.0522807\tvalid_0's l2: 0.0119324\n",
      "[99]\tvalid_0's l1: 0.0522875\tvalid_0's l2: 0.0119322\n",
      "[100]\tvalid_0's l1: 0.0522999\tvalid_0's l2: 0.0119372\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[94]\tvalid_0's l1: 0.0522754\tvalid_0's l2: 0.011932\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['40대 여성 선호도 점수']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['40대 여성 선호도 점수']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "y_train_score_test['40대 여성 선호도 점수'] = y_pred2\n",
    "\n",
    "sum += mean_squared_error(y_pred2, np.array(y_train['40대 여성 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "arabic-developer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0814279\tvalid_0's l2: 0.0168732\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 0.0807357\tvalid_0's l2: 0.0167244\n",
      "[3]\tvalid_0's l1: 0.080342\tvalid_0's l2: 0.0166102\n",
      "[4]\tvalid_0's l1: 0.0797997\tvalid_0's l2: 0.0165062\n",
      "[5]\tvalid_0's l1: 0.0794641\tvalid_0's l2: 0.016412\n",
      "[6]\tvalid_0's l1: 0.0790501\tvalid_0's l2: 0.0163424\n",
      "[7]\tvalid_0's l1: 0.0788784\tvalid_0's l2: 0.0162834\n",
      "[8]\tvalid_0's l1: 0.0785099\tvalid_0's l2: 0.0162248\n",
      "[9]\tvalid_0's l1: 0.0783793\tvalid_0's l2: 0.0161926\n",
      "[10]\tvalid_0's l1: 0.078214\tvalid_0's l2: 0.0161502\n",
      "[11]\tvalid_0's l1: 0.0779213\tvalid_0's l2: 0.0161062\n",
      "[12]\tvalid_0's l1: 0.0778494\tvalid_0's l2: 0.0160889\n",
      "[13]\tvalid_0's l1: 0.0775641\tvalid_0's l2: 0.0160495\n",
      "[14]\tvalid_0's l1: 0.0775201\tvalid_0's l2: 0.016021\n",
      "[15]\tvalid_0's l1: 0.0774638\tvalid_0's l2: 0.0160116\n",
      "[16]\tvalid_0's l1: 0.0772468\tvalid_0's l2: 0.0159839\n",
      "[17]\tvalid_0's l1: 0.077188\tvalid_0's l2: 0.0159795\n",
      "[18]\tvalid_0's l1: 0.0771448\tvalid_0's l2: 0.0159651\n",
      "[19]\tvalid_0's l1: 0.0771046\tvalid_0's l2: 0.0159568\n",
      "[20]\tvalid_0's l1: 0.0770878\tvalid_0's l2: 0.0159568\n",
      "[21]\tvalid_0's l1: 0.0769984\tvalid_0's l2: 0.015945\n",
      "[22]\tvalid_0's l1: 0.0769583\tvalid_0's l2: 0.015933\n",
      "[23]\tvalid_0's l1: 0.0767753\tvalid_0's l2: 0.015909\n",
      "[24]\tvalid_0's l1: 0.0767349\tvalid_0's l2: 0.0159072\n",
      "[25]\tvalid_0's l1: 0.0767204\tvalid_0's l2: 0.0159025\n",
      "[26]\tvalid_0's l1: 0.0767071\tvalid_0's l2: 0.0159035\n",
      "[27]\tvalid_0's l1: 0.0766137\tvalid_0's l2: 0.0158907\n",
      "[28]\tvalid_0's l1: 0.0766165\tvalid_0's l2: 0.0158922\n",
      "[29]\tvalid_0's l1: 0.0765761\tvalid_0's l2: 0.0158934\n",
      "[30]\tvalid_0's l1: 0.0764656\tvalid_0's l2: 0.0158776\n",
      "[31]\tvalid_0's l1: 0.0764479\tvalid_0's l2: 0.0158745\n",
      "[32]\tvalid_0's l1: 0.0764521\tvalid_0's l2: 0.0158715\n",
      "[33]\tvalid_0's l1: 0.0764147\tvalid_0's l2: 0.0158708\n",
      "[34]\tvalid_0's l1: 0.0763651\tvalid_0's l2: 0.0158635\n",
      "[35]\tvalid_0's l1: 0.0763423\tvalid_0's l2: 0.0158654\n",
      "[36]\tvalid_0's l1: 0.076332\tvalid_0's l2: 0.0158677\n",
      "[37]\tvalid_0's l1: 0.0763075\tvalid_0's l2: 0.0158678\n",
      "[38]\tvalid_0's l1: 0.0762229\tvalid_0's l2: 0.0158567\n",
      "[39]\tvalid_0's l1: 0.0762148\tvalid_0's l2: 0.0158569\n",
      "[40]\tvalid_0's l1: 0.0762036\tvalid_0's l2: 0.0158565\n",
      "[41]\tvalid_0's l1: 0.0761949\tvalid_0's l2: 0.0158605\n",
      "[42]\tvalid_0's l1: 0.0761619\tvalid_0's l2: 0.0158572\n",
      "[43]\tvalid_0's l1: 0.0761782\tvalid_0's l2: 0.015864\n",
      "[44]\tvalid_0's l1: 0.0761137\tvalid_0's l2: 0.0158566\n",
      "[45]\tvalid_0's l1: 0.0760896\tvalid_0's l2: 0.0158521\n",
      "[46]\tvalid_0's l1: 0.0760644\tvalid_0's l2: 0.0158514\n",
      "[47]\tvalid_0's l1: 0.0760306\tvalid_0's l2: 0.0158483\n",
      "[48]\tvalid_0's l1: 0.0760252\tvalid_0's l2: 0.0158457\n",
      "[49]\tvalid_0's l1: 0.0760138\tvalid_0's l2: 0.0158443\n",
      "[50]\tvalid_0's l1: 0.0760211\tvalid_0's l2: 0.0158473\n",
      "[51]\tvalid_0's l1: 0.0760143\tvalid_0's l2: 0.0158478\n",
      "[52]\tvalid_0's l1: 0.0759912\tvalid_0's l2: 0.015846\n",
      "[53]\tvalid_0's l1: 0.075962\tvalid_0's l2: 0.0158382\n",
      "[54]\tvalid_0's l1: 0.0759636\tvalid_0's l2: 0.0158519\n",
      "[55]\tvalid_0's l1: 0.0759242\tvalid_0's l2: 0.0158454\n",
      "[56]\tvalid_0's l1: 0.0758972\tvalid_0's l2: 0.0158419\n",
      "[57]\tvalid_0's l1: 0.0759001\tvalid_0's l2: 0.0158424\n",
      "[58]\tvalid_0's l1: 0.075881\tvalid_0's l2: 0.0158426\n",
      "[59]\tvalid_0's l1: 0.0758737\tvalid_0's l2: 0.0158438\n",
      "[60]\tvalid_0's l1: 0.0758629\tvalid_0's l2: 0.0158485\n",
      "[61]\tvalid_0's l1: 0.0758672\tvalid_0's l2: 0.0158521\n",
      "[62]\tvalid_0's l1: 0.0758523\tvalid_0's l2: 0.0158514\n",
      "[63]\tvalid_0's l1: 0.0758429\tvalid_0's l2: 0.015854\n",
      "[64]\tvalid_0's l1: 0.0758497\tvalid_0's l2: 0.0158601\n",
      "[65]\tvalid_0's l1: 0.0758014\tvalid_0's l2: 0.0158547\n",
      "[66]\tvalid_0's l1: 0.0757952\tvalid_0's l2: 0.0158558\n",
      "[67]\tvalid_0's l1: 0.0758059\tvalid_0's l2: 0.0158591\n",
      "[68]\tvalid_0's l1: 0.0757836\tvalid_0's l2: 0.0158576\n",
      "[69]\tvalid_0's l1: 0.0757812\tvalid_0's l2: 0.0158617\n",
      "[70]\tvalid_0's l1: 0.0757691\tvalid_0's l2: 0.0158664\n",
      "[71]\tvalid_0's l1: 0.0757726\tvalid_0's l2: 0.0158694\n",
      "[72]\tvalid_0's l1: 0.0757742\tvalid_0's l2: 0.0158707\n",
      "[73]\tvalid_0's l1: 0.0757555\tvalid_0's l2: 0.0158699\n",
      "[74]\tvalid_0's l1: 0.0757333\tvalid_0's l2: 0.015866\n",
      "[75]\tvalid_0's l1: 0.0757263\tvalid_0's l2: 0.0158671\n",
      "[76]\tvalid_0's l1: 0.0757036\tvalid_0's l2: 0.0158708\n",
      "[77]\tvalid_0's l1: 0.0756928\tvalid_0's l2: 0.0158755\n",
      "[78]\tvalid_0's l1: 0.0756838\tvalid_0's l2: 0.0158766\n",
      "[79]\tvalid_0's l1: 0.0756761\tvalid_0's l2: 0.0158772\n",
      "[80]\tvalid_0's l1: 0.0756612\tvalid_0's l2: 0.0158752\n",
      "[81]\tvalid_0's l1: 0.0756629\tvalid_0's l2: 0.0158835\n",
      "[82]\tvalid_0's l1: 0.0756594\tvalid_0's l2: 0.0158832\n",
      "[83]\tvalid_0's l1: 0.0756628\tvalid_0's l2: 0.0158924\n",
      "[84]\tvalid_0's l1: 0.0756474\tvalid_0's l2: 0.0158978\n",
      "[85]\tvalid_0's l1: 0.0756422\tvalid_0's l2: 0.0158998\n",
      "[86]\tvalid_0's l1: 0.0756171\tvalid_0's l2: 0.0158959\n",
      "[87]\tvalid_0's l1: 0.0756137\tvalid_0's l2: 0.0158999\n",
      "[88]\tvalid_0's l1: 0.0756118\tvalid_0's l2: 0.0159014\n",
      "[89]\tvalid_0's l1: 0.0756053\tvalid_0's l2: 0.0158999\n",
      "[90]\tvalid_0's l1: 0.0755964\tvalid_0's l2: 0.0158994\n",
      "[91]\tvalid_0's l1: 0.0755856\tvalid_0's l2: 0.0158969\n",
      "[92]\tvalid_0's l1: 0.0755865\tvalid_0's l2: 0.0159001\n",
      "[93]\tvalid_0's l1: 0.0755786\tvalid_0's l2: 0.0158998\n",
      "[94]\tvalid_0's l1: 0.0755747\tvalid_0's l2: 0.0159003\n",
      "[95]\tvalid_0's l1: 0.0755693\tvalid_0's l2: 0.0158999\n",
      "[96]\tvalid_0's l1: 0.0755746\tvalid_0's l2: 0.0159078\n",
      "[97]\tvalid_0's l1: 0.0755769\tvalid_0's l2: 0.015908\n",
      "[98]\tvalid_0's l1: 0.0755551\tvalid_0's l2: 0.0159049\n",
      "[99]\tvalid_0's l1: 0.0755387\tvalid_0's l2: 0.015905\n",
      "[100]\tvalid_0's l1: 0.0755344\tvalid_0's l2: 0.0159045\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 0.0755344\tvalid_0's l2: 0.0159045\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['50대 남성 선호도 점수']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['50대 남성 선호도 점수']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "y_train_score_test['50대 남성 선호도 점수'] = y_pred2\n",
    "\n",
    "sum += mean_squared_error(y_pred2, np.array(y_train['50대 남성 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "pregnant-visibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0625587\tvalid_0's l2: 0.0101356\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 0.0617401\tvalid_0's l2: 0.0100094\n",
      "[3]\tvalid_0's l1: 0.0610637\tvalid_0's l2: 0.00990851\n",
      "[4]\tvalid_0's l1: 0.0604973\tvalid_0's l2: 0.00982892\n",
      "[5]\tvalid_0's l1: 0.0600191\tvalid_0's l2: 0.00975731\n",
      "[6]\tvalid_0's l1: 0.0595754\tvalid_0's l2: 0.00970035\n",
      "[7]\tvalid_0's l1: 0.0592423\tvalid_0's l2: 0.0096606\n",
      "[8]\tvalid_0's l1: 0.0588298\tvalid_0's l2: 0.00961011\n",
      "[9]\tvalid_0's l1: 0.0585907\tvalid_0's l2: 0.00958429\n",
      "[10]\tvalid_0's l1: 0.0582764\tvalid_0's l2: 0.00955318\n",
      "[11]\tvalid_0's l1: 0.0579835\tvalid_0's l2: 0.00951918\n",
      "[12]\tvalid_0's l1: 0.0578044\tvalid_0's l2: 0.00950151\n",
      "[13]\tvalid_0's l1: 0.0575905\tvalid_0's l2: 0.00948534\n",
      "[14]\tvalid_0's l1: 0.0573617\tvalid_0's l2: 0.00946065\n",
      "[15]\tvalid_0's l1: 0.0572348\tvalid_0's l2: 0.0094528\n",
      "[16]\tvalid_0's l1: 0.0570295\tvalid_0's l2: 0.00943077\n",
      "[17]\tvalid_0's l1: 0.0569488\tvalid_0's l2: 0.00943173\n",
      "[18]\tvalid_0's l1: 0.0567917\tvalid_0's l2: 0.00941358\n",
      "[19]\tvalid_0's l1: 0.0567359\tvalid_0's l2: 0.00940459\n",
      "[20]\tvalid_0's l1: 0.0566672\tvalid_0's l2: 0.00940213\n",
      "[21]\tvalid_0's l1: 0.056594\tvalid_0's l2: 0.00939285\n",
      "[22]\tvalid_0's l1: 0.0564994\tvalid_0's l2: 0.0093832\n",
      "[23]\tvalid_0's l1: 0.0564593\tvalid_0's l2: 0.0093788\n",
      "[24]\tvalid_0's l1: 0.0564136\tvalid_0's l2: 0.00937701\n",
      "[25]\tvalid_0's l1: 0.0563053\tvalid_0's l2: 0.00936833\n",
      "[26]\tvalid_0's l1: 0.0562607\tvalid_0's l2: 0.00936448\n",
      "[27]\tvalid_0's l1: 0.0562353\tvalid_0's l2: 0.00936724\n",
      "[28]\tvalid_0's l1: 0.0561783\tvalid_0's l2: 0.00936263\n",
      "[29]\tvalid_0's l1: 0.0560891\tvalid_0's l2: 0.00935279\n",
      "[30]\tvalid_0's l1: 0.0560554\tvalid_0's l2: 0.00935414\n",
      "[31]\tvalid_0's l1: 0.0560079\tvalid_0's l2: 0.00935787\n",
      "[32]\tvalid_0's l1: 0.0559777\tvalid_0's l2: 0.00935525\n",
      "[33]\tvalid_0's l1: 0.0559321\tvalid_0's l2: 0.00935005\n",
      "[34]\tvalid_0's l1: 0.0558824\tvalid_0's l2: 0.00934708\n",
      "[35]\tvalid_0's l1: 0.0558335\tvalid_0's l2: 0.00934367\n",
      "[36]\tvalid_0's l1: 0.0558143\tvalid_0's l2: 0.00934408\n",
      "[37]\tvalid_0's l1: 0.0557617\tvalid_0's l2: 0.00933896\n",
      "[38]\tvalid_0's l1: 0.0557284\tvalid_0's l2: 0.00933907\n",
      "[39]\tvalid_0's l1: 0.0557261\tvalid_0's l2: 0.00934594\n",
      "[40]\tvalid_0's l1: 0.0556994\tvalid_0's l2: 0.00934317\n",
      "[41]\tvalid_0's l1: 0.0556651\tvalid_0's l2: 0.00933985\n",
      "[42]\tvalid_0's l1: 0.0556315\tvalid_0's l2: 0.00933865\n",
      "[43]\tvalid_0's l1: 0.055602\tvalid_0's l2: 0.0093409\n",
      "[44]\tvalid_0's l1: 0.0555664\tvalid_0's l2: 0.00933699\n",
      "[45]\tvalid_0's l1: 0.0555422\tvalid_0's l2: 0.00933788\n",
      "[46]\tvalid_0's l1: 0.055502\tvalid_0's l2: 0.00933489\n",
      "[47]\tvalid_0's l1: 0.055476\tvalid_0's l2: 0.00933394\n",
      "[48]\tvalid_0's l1: 0.0554785\tvalid_0's l2: 0.00934071\n",
      "[49]\tvalid_0's l1: 0.0554599\tvalid_0's l2: 0.00933903\n",
      "[50]\tvalid_0's l1: 0.0554179\tvalid_0's l2: 0.00933393\n",
      "[51]\tvalid_0's l1: 0.055397\tvalid_0's l2: 0.00933307\n",
      "[52]\tvalid_0's l1: 0.0553668\tvalid_0's l2: 0.00933201\n",
      "[53]\tvalid_0's l1: 0.0553353\tvalid_0's l2: 0.00932998\n",
      "[54]\tvalid_0's l1: 0.0553125\tvalid_0's l2: 0.00933005\n",
      "[55]\tvalid_0's l1: 0.0552944\tvalid_0's l2: 0.00933138\n",
      "[56]\tvalid_0's l1: 0.0552726\tvalid_0's l2: 0.00932931\n",
      "[57]\tvalid_0's l1: 0.0552527\tvalid_0's l2: 0.0093284\n",
      "[58]\tvalid_0's l1: 0.0552304\tvalid_0's l2: 0.00932693\n",
      "[59]\tvalid_0's l1: 0.0552246\tvalid_0's l2: 0.00933286\n",
      "[60]\tvalid_0's l1: 0.0552098\tvalid_0's l2: 0.00933377\n",
      "[61]\tvalid_0's l1: 0.055189\tvalid_0's l2: 0.00933357\n",
      "[62]\tvalid_0's l1: 0.0551872\tvalid_0's l2: 0.00933417\n",
      "[63]\tvalid_0's l1: 0.0551451\tvalid_0's l2: 0.00932921\n",
      "[64]\tvalid_0's l1: 0.055136\tvalid_0's l2: 0.00932988\n",
      "[65]\tvalid_0's l1: 0.0551102\tvalid_0's l2: 0.00932851\n",
      "[66]\tvalid_0's l1: 0.055099\tvalid_0's l2: 0.00933069\n",
      "[67]\tvalid_0's l1: 0.0550938\tvalid_0's l2: 0.00933648\n",
      "[68]\tvalid_0's l1: 0.0550684\tvalid_0's l2: 0.00933417\n",
      "[69]\tvalid_0's l1: 0.0550623\tvalid_0's l2: 0.00933672\n",
      "[70]\tvalid_0's l1: 0.0550473\tvalid_0's l2: 0.00933704\n",
      "[71]\tvalid_0's l1: 0.055042\tvalid_0's l2: 0.00933736\n",
      "[72]\tvalid_0's l1: 0.0550382\tvalid_0's l2: 0.0093382\n",
      "[73]\tvalid_0's l1: 0.0550123\tvalid_0's l2: 0.00933872\n",
      "[74]\tvalid_0's l1: 0.0550019\tvalid_0's l2: 0.00933586\n",
      "[75]\tvalid_0's l1: 0.0549833\tvalid_0's l2: 0.00933448\n",
      "[76]\tvalid_0's l1: 0.0549541\tvalid_0's l2: 0.00933106\n",
      "[77]\tvalid_0's l1: 0.0549248\tvalid_0's l2: 0.00932911\n",
      "[78]\tvalid_0's l1: 0.0549012\tvalid_0's l2: 0.00932981\n",
      "[79]\tvalid_0's l1: 0.0548938\tvalid_0's l2: 0.00932985\n",
      "[80]\tvalid_0's l1: 0.0548875\tvalid_0's l2: 0.0093298\n",
      "[81]\tvalid_0's l1: 0.0548767\tvalid_0's l2: 0.00932998\n",
      "[82]\tvalid_0's l1: 0.0548667\tvalid_0's l2: 0.00932989\n",
      "[83]\tvalid_0's l1: 0.054852\tvalid_0's l2: 0.00932773\n",
      "[84]\tvalid_0's l1: 0.0548345\tvalid_0's l2: 0.00932807\n",
      "[85]\tvalid_0's l1: 0.0548294\tvalid_0's l2: 0.00932795\n",
      "[86]\tvalid_0's l1: 0.0548201\tvalid_0's l2: 0.0093286\n",
      "[87]\tvalid_0's l1: 0.0548081\tvalid_0's l2: 0.00933007\n",
      "[88]\tvalid_0's l1: 0.0547995\tvalid_0's l2: 0.00933359\n",
      "[89]\tvalid_0's l1: 0.0547824\tvalid_0's l2: 0.0093321\n",
      "[90]\tvalid_0's l1: 0.0547826\tvalid_0's l2: 0.00933407\n",
      "[91]\tvalid_0's l1: 0.0547765\tvalid_0's l2: 0.00933554\n",
      "[92]\tvalid_0's l1: 0.0547599\tvalid_0's l2: 0.00933431\n",
      "[93]\tvalid_0's l1: 0.0547529\tvalid_0's l2: 0.00933816\n",
      "[94]\tvalid_0's l1: 0.0547509\tvalid_0's l2: 0.00933833\n",
      "[95]\tvalid_0's l1: 0.0547516\tvalid_0's l2: 0.00934004\n",
      "[96]\tvalid_0's l1: 0.0547441\tvalid_0's l2: 0.00934115\n",
      "[97]\tvalid_0's l1: 0.0547335\tvalid_0's l2: 0.00934027\n",
      "[98]\tvalid_0's l1: 0.0547133\tvalid_0's l2: 0.0093395\n",
      "[99]\tvalid_0's l1: 0.0547078\tvalid_0's l2: 0.00934096\n",
      "[100]\tvalid_0's l1: 0.0547025\tvalid_0's l2: 0.00934174\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 0.0547025\tvalid_0's l2: 0.00934174\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['50대 여성 선호도 점수']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['50대 여성 선호도 점수']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "y_train_score_test['50대 여성 선호도 점수'] = y_pred2\n",
    "\n",
    "sum += mean_squared_error(y_pred2, np.array(y_train['50대 여성 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "revised-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.095362\tvalid_0's l2: 0.0186499\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 0.0947675\tvalid_0's l2: 0.0184712\n",
      "[3]\tvalid_0's l1: 0.0941606\tvalid_0's l2: 0.0183152\n",
      "[4]\tvalid_0's l1: 0.0936454\tvalid_0's l2: 0.018185\n",
      "[5]\tvalid_0's l1: 0.0931024\tvalid_0's l2: 0.0180706\n",
      "[6]\tvalid_0's l1: 0.0927149\tvalid_0's l2: 0.0179843\n",
      "[7]\tvalid_0's l1: 0.0922173\tvalid_0's l2: 0.0178988\n",
      "[8]\tvalid_0's l1: 0.0919425\tvalid_0's l2: 0.0178396\n",
      "[9]\tvalid_0's l1: 0.0915761\tvalid_0's l2: 0.0177817\n",
      "[10]\tvalid_0's l1: 0.0914136\tvalid_0's l2: 0.0177493\n",
      "[11]\tvalid_0's l1: 0.0912657\tvalid_0's l2: 0.0177242\n",
      "[12]\tvalid_0's l1: 0.0909106\tvalid_0's l2: 0.0176716\n",
      "[13]\tvalid_0's l1: 0.0907712\tvalid_0's l2: 0.0176529\n",
      "[14]\tvalid_0's l1: 0.0905291\tvalid_0's l2: 0.0176126\n",
      "[15]\tvalid_0's l1: 0.0903037\tvalid_0's l2: 0.0175795\n",
      "[16]\tvalid_0's l1: 0.0902126\tvalid_0's l2: 0.0175584\n",
      "[17]\tvalid_0's l1: 0.0899887\tvalid_0's l2: 0.0175278\n",
      "[18]\tvalid_0's l1: 0.0898614\tvalid_0's l2: 0.0175134\n",
      "[19]\tvalid_0's l1: 0.0896619\tvalid_0's l2: 0.017488\n",
      "[20]\tvalid_0's l1: 0.089591\tvalid_0's l2: 0.0174744\n",
      "[21]\tvalid_0's l1: 0.0895231\tvalid_0's l2: 0.0174689\n",
      "[22]\tvalid_0's l1: 0.089384\tvalid_0's l2: 0.0174487\n",
      "[23]\tvalid_0's l1: 0.0892292\tvalid_0's l2: 0.0174281\n",
      "[24]\tvalid_0's l1: 0.0891455\tvalid_0's l2: 0.0174179\n",
      "[25]\tvalid_0's l1: 0.0891047\tvalid_0's l2: 0.0174133\n",
      "[26]\tvalid_0's l1: 0.0889931\tvalid_0's l2: 0.0174021\n",
      "[27]\tvalid_0's l1: 0.0888459\tvalid_0's l2: 0.0173864\n",
      "[28]\tvalid_0's l1: 0.088738\tvalid_0's l2: 0.0173708\n",
      "[29]\tvalid_0's l1: 0.0887082\tvalid_0's l2: 0.0173693\n",
      "[30]\tvalid_0's l1: 0.0886321\tvalid_0's l2: 0.0173649\n",
      "[31]\tvalid_0's l1: 0.0885575\tvalid_0's l2: 0.0173571\n",
      "[32]\tvalid_0's l1: 0.0884805\tvalid_0's l2: 0.0173468\n",
      "[33]\tvalid_0's l1: 0.0884197\tvalid_0's l2: 0.0173394\n",
      "[34]\tvalid_0's l1: 0.08837\tvalid_0's l2: 0.0173291\n",
      "[35]\tvalid_0's l1: 0.0882982\tvalid_0's l2: 0.0173218\n",
      "[36]\tvalid_0's l1: 0.0882566\tvalid_0's l2: 0.0173196\n",
      "[37]\tvalid_0's l1: 0.0882122\tvalid_0's l2: 0.0173131\n",
      "[38]\tvalid_0's l1: 0.0881792\tvalid_0's l2: 0.0173165\n",
      "[39]\tvalid_0's l1: 0.088134\tvalid_0's l2: 0.0173145\n",
      "[40]\tvalid_0's l1: 0.0880475\tvalid_0's l2: 0.0173052\n",
      "[41]\tvalid_0's l1: 0.0880235\tvalid_0's l2: 0.0173029\n",
      "[42]\tvalid_0's l1: 0.0879969\tvalid_0's l2: 0.0173049\n",
      "[43]\tvalid_0's l1: 0.0879544\tvalid_0's l2: 0.0173032\n",
      "[44]\tvalid_0's l1: 0.0879232\tvalid_0's l2: 0.0173032\n",
      "[45]\tvalid_0's l1: 0.0878923\tvalid_0's l2: 0.0172996\n",
      "[46]\tvalid_0's l1: 0.0878632\tvalid_0's l2: 0.0172946\n",
      "[47]\tvalid_0's l1: 0.0878175\tvalid_0's l2: 0.0172893\n",
      "[48]\tvalid_0's l1: 0.0877617\tvalid_0's l2: 0.0172885\n",
      "[49]\tvalid_0's l1: 0.0877216\tvalid_0's l2: 0.0172832\n",
      "[50]\tvalid_0's l1: 0.0876946\tvalid_0's l2: 0.0172774\n",
      "[51]\tvalid_0's l1: 0.0876633\tvalid_0's l2: 0.0172752\n",
      "[52]\tvalid_0's l1: 0.087655\tvalid_0's l2: 0.0172809\n",
      "[53]\tvalid_0's l1: 0.08761\tvalid_0's l2: 0.0172759\n",
      "[54]\tvalid_0's l1: 0.0875948\tvalid_0's l2: 0.0172772\n",
      "[55]\tvalid_0's l1: 0.0875687\tvalid_0's l2: 0.0172749\n",
      "[56]\tvalid_0's l1: 0.0875527\tvalid_0's l2: 0.0172747\n",
      "[57]\tvalid_0's l1: 0.0875274\tvalid_0's l2: 0.0172735\n",
      "[58]\tvalid_0's l1: 0.0875024\tvalid_0's l2: 0.0172741\n",
      "[59]\tvalid_0's l1: 0.0874769\tvalid_0's l2: 0.0172713\n",
      "[60]\tvalid_0's l1: 0.0874664\tvalid_0's l2: 0.0172729\n",
      "[61]\tvalid_0's l1: 0.0874473\tvalid_0's l2: 0.0172709\n",
      "[62]\tvalid_0's l1: 0.087413\tvalid_0's l2: 0.0172703\n",
      "[63]\tvalid_0's l1: 0.0873807\tvalid_0's l2: 0.0172718\n",
      "[64]\tvalid_0's l1: 0.0873678\tvalid_0's l2: 0.0172724\n",
      "[65]\tvalid_0's l1: 0.087354\tvalid_0's l2: 0.0172741\n",
      "[66]\tvalid_0's l1: 0.0873205\tvalid_0's l2: 0.0172716\n",
      "[67]\tvalid_0's l1: 0.087292\tvalid_0's l2: 0.0172701\n",
      "[68]\tvalid_0's l1: 0.0872684\tvalid_0's l2: 0.0172694\n",
      "[69]\tvalid_0's l1: 0.0872509\tvalid_0's l2: 0.0172709\n",
      "[70]\tvalid_0's l1: 0.0872366\tvalid_0's l2: 0.0172696\n",
      "[71]\tvalid_0's l1: 0.0872119\tvalid_0's l2: 0.0172672\n",
      "[72]\tvalid_0's l1: 0.0872061\tvalid_0's l2: 0.0172663\n",
      "[73]\tvalid_0's l1: 0.0871838\tvalid_0's l2: 0.0172644\n",
      "[74]\tvalid_0's l1: 0.0871681\tvalid_0's l2: 0.0172649\n",
      "[75]\tvalid_0's l1: 0.0871264\tvalid_0's l2: 0.0172652\n",
      "[76]\tvalid_0's l1: 0.0871029\tvalid_0's l2: 0.0172619\n",
      "[77]\tvalid_0's l1: 0.0871032\tvalid_0's l2: 0.0172633\n",
      "[78]\tvalid_0's l1: 0.0870987\tvalid_0's l2: 0.0172635\n",
      "[79]\tvalid_0's l1: 0.0870425\tvalid_0's l2: 0.0172568\n",
      "[80]\tvalid_0's l1: 0.0870361\tvalid_0's l2: 0.017259\n",
      "[81]\tvalid_0's l1: 0.087019\tvalid_0's l2: 0.017258\n",
      "[82]\tvalid_0's l1: 0.0870072\tvalid_0's l2: 0.0172593\n",
      "[83]\tvalid_0's l1: 0.0869783\tvalid_0's l2: 0.0172553\n",
      "[84]\tvalid_0's l1: 0.0869577\tvalid_0's l2: 0.0172553\n",
      "[85]\tvalid_0's l1: 0.0869294\tvalid_0's l2: 0.0172559\n",
      "[86]\tvalid_0's l1: 0.0869194\tvalid_0's l2: 0.0172551\n",
      "[87]\tvalid_0's l1: 0.0868911\tvalid_0's l2: 0.0172531\n",
      "[88]\tvalid_0's l1: 0.0868785\tvalid_0's l2: 0.0172519\n",
      "[89]\tvalid_0's l1: 0.0868488\tvalid_0's l2: 0.0172511\n",
      "[90]\tvalid_0's l1: 0.0868347\tvalid_0's l2: 0.0172472\n",
      "[91]\tvalid_0's l1: 0.0868277\tvalid_0's l2: 0.0172479\n",
      "[92]\tvalid_0's l1: 0.0868064\tvalid_0's l2: 0.0172471\n",
      "[93]\tvalid_0's l1: 0.0867929\tvalid_0's l2: 0.0172452\n",
      "[94]\tvalid_0's l1: 0.0867878\tvalid_0's l2: 0.0172504\n",
      "[95]\tvalid_0's l1: 0.0867896\tvalid_0's l2: 0.0172539\n",
      "[96]\tvalid_0's l1: 0.0867686\tvalid_0's l2: 0.0172509\n",
      "[97]\tvalid_0's l1: 0.0867581\tvalid_0's l2: 0.0172505\n",
      "[98]\tvalid_0's l1: 0.0867532\tvalid_0's l2: 0.0172528\n",
      "[99]\tvalid_0's l1: 0.0867447\tvalid_0's l2: 0.0172535\n",
      "[100]\tvalid_0's l1: 0.0867273\tvalid_0's l2: 0.0172532\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 0.0867273\tvalid_0's l2: 0.0172532\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['60대 남성 선호도 점수']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['60대 남성 선호도 점수']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "y_train_score_test['60대 남성 선호도 점수'] = y_pred2\n",
    "\n",
    "sum += mean_squared_error(y_pred2, np.array(y_train['60대 남성 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "olive-symphony",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0784001\tvalid_0's l2: 0.0126268\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\tvalid_0's l1: 0.0774889\tvalid_0's l2: 0.0124579\n",
      "[3]\tvalid_0's l1: 0.0767229\tvalid_0's l2: 0.0123172\n",
      "[4]\tvalid_0's l1: 0.0760652\tvalid_0's l2: 0.0122116\n",
      "[5]\tvalid_0's l1: 0.0754938\tvalid_0's l2: 0.0121156\n",
      "[6]\tvalid_0's l1: 0.0749604\tvalid_0's l2: 0.0120387\n",
      "[7]\tvalid_0's l1: 0.0745139\tvalid_0's l2: 0.0119698\n",
      "[8]\tvalid_0's l1: 0.074078\tvalid_0's l2: 0.0119163\n",
      "[9]\tvalid_0's l1: 0.0737821\tvalid_0's l2: 0.0118712\n",
      "[10]\tvalid_0's l1: 0.0734538\tvalid_0's l2: 0.0118341\n",
      "[11]\tvalid_0's l1: 0.0731552\tvalid_0's l2: 0.0118059\n",
      "[12]\tvalid_0's l1: 0.0728959\tvalid_0's l2: 0.0117717\n",
      "[13]\tvalid_0's l1: 0.0727281\tvalid_0's l2: 0.0117548\n",
      "[14]\tvalid_0's l1: 0.0725434\tvalid_0's l2: 0.0117379\n",
      "[15]\tvalid_0's l1: 0.0723635\tvalid_0's l2: 0.0117147\n",
      "[16]\tvalid_0's l1: 0.0722242\tvalid_0's l2: 0.0117047\n",
      "[17]\tvalid_0's l1: 0.0720691\tvalid_0's l2: 0.0116881\n",
      "[18]\tvalid_0's l1: 0.0718487\tvalid_0's l2: 0.011671\n",
      "[19]\tvalid_0's l1: 0.0717544\tvalid_0's l2: 0.0116632\n",
      "[20]\tvalid_0's l1: 0.0716619\tvalid_0's l2: 0.0116505\n",
      "[21]\tvalid_0's l1: 0.0714525\tvalid_0's l2: 0.0116338\n",
      "[22]\tvalid_0's l1: 0.0713882\tvalid_0's l2: 0.011627\n",
      "[23]\tvalid_0's l1: 0.0712925\tvalid_0's l2: 0.0116131\n",
      "[24]\tvalid_0's l1: 0.0711458\tvalid_0's l2: 0.0116\n",
      "[25]\tvalid_0's l1: 0.0710404\tvalid_0's l2: 0.011591\n",
      "[26]\tvalid_0's l1: 0.0709384\tvalid_0's l2: 0.0115784\n",
      "[27]\tvalid_0's l1: 0.0708105\tvalid_0's l2: 0.0115694\n",
      "[28]\tvalid_0's l1: 0.0707105\tvalid_0's l2: 0.0115591\n",
      "[29]\tvalid_0's l1: 0.0706234\tvalid_0's l2: 0.0115482\n",
      "[30]\tvalid_0's l1: 0.0705894\tvalid_0's l2: 0.0115459\n",
      "[31]\tvalid_0's l1: 0.0705417\tvalid_0's l2: 0.0115438\n",
      "[32]\tvalid_0's l1: 0.0704495\tvalid_0's l2: 0.0115386\n",
      "[33]\tvalid_0's l1: 0.0704041\tvalid_0's l2: 0.011535\n",
      "[34]\tvalid_0's l1: 0.0703456\tvalid_0's l2: 0.0115271\n",
      "[35]\tvalid_0's l1: 0.0703056\tvalid_0's l2: 0.0115223\n",
      "[36]\tvalid_0's l1: 0.0702545\tvalid_0's l2: 0.0115189\n",
      "[37]\tvalid_0's l1: 0.0701831\tvalid_0's l2: 0.0115114\n",
      "[38]\tvalid_0's l1: 0.0701061\tvalid_0's l2: 0.0115089\n",
      "[39]\tvalid_0's l1: 0.070092\tvalid_0's l2: 0.0115097\n",
      "[40]\tvalid_0's l1: 0.0700804\tvalid_0's l2: 0.0115116\n",
      "[41]\tvalid_0's l1: 0.0700417\tvalid_0's l2: 0.0115057\n",
      "[42]\tvalid_0's l1: 0.0699743\tvalid_0's l2: 0.0114965\n",
      "[43]\tvalid_0's l1: 0.0699494\tvalid_0's l2: 0.0114944\n",
      "[44]\tvalid_0's l1: 0.0699137\tvalid_0's l2: 0.01149\n",
      "[45]\tvalid_0's l1: 0.0698638\tvalid_0's l2: 0.0114862\n",
      "[46]\tvalid_0's l1: 0.0698224\tvalid_0's l2: 0.0114826\n",
      "[47]\tvalid_0's l1: 0.0697751\tvalid_0's l2: 0.0114811\n",
      "[48]\tvalid_0's l1: 0.069765\tvalid_0's l2: 0.0114845\n",
      "[49]\tvalid_0's l1: 0.0697487\tvalid_0's l2: 0.0114855\n",
      "[50]\tvalid_0's l1: 0.0697111\tvalid_0's l2: 0.0114855\n",
      "[51]\tvalid_0's l1: 0.0696776\tvalid_0's l2: 0.0114829\n",
      "[52]\tvalid_0's l1: 0.0696366\tvalid_0's l2: 0.01148\n",
      "[53]\tvalid_0's l1: 0.0695824\tvalid_0's l2: 0.0114778\n",
      "[54]\tvalid_0's l1: 0.0695481\tvalid_0's l2: 0.0114726\n",
      "[55]\tvalid_0's l1: 0.0695068\tvalid_0's l2: 0.0114701\n",
      "[56]\tvalid_0's l1: 0.0694842\tvalid_0's l2: 0.011467\n",
      "[57]\tvalid_0's l1: 0.0694445\tvalid_0's l2: 0.0114633\n",
      "[58]\tvalid_0's l1: 0.0694337\tvalid_0's l2: 0.0114651\n",
      "[59]\tvalid_0's l1: 0.0694224\tvalid_0's l2: 0.0114659\n",
      "[60]\tvalid_0's l1: 0.0693993\tvalid_0's l2: 0.0114651\n",
      "[61]\tvalid_0's l1: 0.0693742\tvalid_0's l2: 0.011464\n",
      "[62]\tvalid_0's l1: 0.0693555\tvalid_0's l2: 0.0114632\n",
      "[63]\tvalid_0's l1: 0.069327\tvalid_0's l2: 0.0114617\n",
      "[64]\tvalid_0's l1: 0.0693065\tvalid_0's l2: 0.0114618\n",
      "[65]\tvalid_0's l1: 0.0692781\tvalid_0's l2: 0.0114599\n",
      "[66]\tvalid_0's l1: 0.0692561\tvalid_0's l2: 0.0114569\n",
      "[67]\tvalid_0's l1: 0.0692346\tvalid_0's l2: 0.0114545\n",
      "[68]\tvalid_0's l1: 0.0691963\tvalid_0's l2: 0.0114511\n",
      "[69]\tvalid_0's l1: 0.069171\tvalid_0's l2: 0.0114524\n",
      "[70]\tvalid_0's l1: 0.0691382\tvalid_0's l2: 0.0114495\n",
      "[71]\tvalid_0's l1: 0.0691214\tvalid_0's l2: 0.0114493\n",
      "[72]\tvalid_0's l1: 0.0691096\tvalid_0's l2: 0.01145\n",
      "[73]\tvalid_0's l1: 0.0691027\tvalid_0's l2: 0.0114513\n",
      "[74]\tvalid_0's l1: 0.069082\tvalid_0's l2: 0.0114516\n",
      "[75]\tvalid_0's l1: 0.0690652\tvalid_0's l2: 0.0114514\n",
      "[76]\tvalid_0's l1: 0.0690363\tvalid_0's l2: 0.0114503\n",
      "[77]\tvalid_0's l1: 0.0690182\tvalid_0's l2: 0.0114482\n",
      "[78]\tvalid_0's l1: 0.0690122\tvalid_0's l2: 0.0114495\n",
      "[79]\tvalid_0's l1: 0.0689811\tvalid_0's l2: 0.0114472\n",
      "[80]\tvalid_0's l1: 0.0689714\tvalid_0's l2: 0.011447\n",
      "[81]\tvalid_0's l1: 0.068954\tvalid_0's l2: 0.011447\n",
      "[82]\tvalid_0's l1: 0.0689421\tvalid_0's l2: 0.0114457\n",
      "[83]\tvalid_0's l1: 0.0689189\tvalid_0's l2: 0.011443\n",
      "[84]\tvalid_0's l1: 0.0689196\tvalid_0's l2: 0.0114461\n",
      "[85]\tvalid_0's l1: 0.0689122\tvalid_0's l2: 0.0114461\n",
      "[86]\tvalid_0's l1: 0.0689073\tvalid_0's l2: 0.0114487\n",
      "[87]\tvalid_0's l1: 0.0688747\tvalid_0's l2: 0.0114462\n",
      "[88]\tvalid_0's l1: 0.0688553\tvalid_0's l2: 0.0114462\n",
      "[89]\tvalid_0's l1: 0.0688468\tvalid_0's l2: 0.0114488\n",
      "[90]\tvalid_0's l1: 0.068837\tvalid_0's l2: 0.0114481\n",
      "[91]\tvalid_0's l1: 0.0688303\tvalid_0's l2: 0.0114484\n",
      "[92]\tvalid_0's l1: 0.068834\tvalid_0's l2: 0.0114517\n",
      "[93]\tvalid_0's l1: 0.0688111\tvalid_0's l2: 0.0114505\n",
      "[94]\tvalid_0's l1: 0.0687905\tvalid_0's l2: 0.0114492\n",
      "[95]\tvalid_0's l1: 0.0687777\tvalid_0's l2: 0.01145\n",
      "[96]\tvalid_0's l1: 0.0687674\tvalid_0's l2: 0.0114511\n",
      "[97]\tvalid_0's l1: 0.0687524\tvalid_0's l2: 0.0114502\n",
      "[98]\tvalid_0's l1: 0.0687392\tvalid_0's l2: 0.0114514\n",
      "[99]\tvalid_0's l1: 0.0687342\tvalid_0's l2: 0.0114521\n",
      "[100]\tvalid_0's l1: 0.0687323\tvalid_0's l2: 0.0114525\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 0.0687323\tvalid_0's l2: 0.0114525\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train.iloc[:, 1:], np.array(y_train['60대 여성 선호도 점수']),\n",
    "        eval_set=[(X_test.iloc[:, 1:], np.array(y_test['60대 여성 선호도 점수']))],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=1000)\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "\n",
    "y_pred2 = gbm.predict(X_train.iloc[:, 1:], num_iteration=gbm.best_iteration_)\n",
    "y_train_score_test['60대 여성 선호도 점수'] = y_pred2\n",
    "\n",
    "sum += mean_squared_error(y_pred2, np.array(y_train['60대 여성 선호도 점수']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "intimate-acquisition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 157.35224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('The rmse of prediction is:', round(mean_squared_error(y_pred, np.array(y_train['합계'])) ** 0.5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "danish-phoenix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56268, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_score_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "medical-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20대 남성 선호도 점수</th>\n",
       "      <th>20대 여성 선호도 점수</th>\n",
       "      <th>30대 남성 선호도 점수</th>\n",
       "      <th>30대 여성 선호도 점수</th>\n",
       "      <th>40대 남성 선호도 점수</th>\n",
       "      <th>40대 여성 선호도 점수</th>\n",
       "      <th>50대 남성 선호도 점수</th>\n",
       "      <th>50대 여성 선호도 점수</th>\n",
       "      <th>60대 남성 선호도 점수</th>\n",
       "      <th>60대 여성 선호도 점수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041315</td>\n",
       "      <td>0.054925</td>\n",
       "      <td>0.062113</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.114829</td>\n",
       "      <td>0.180720</td>\n",
       "      <td>0.177137</td>\n",
       "      <td>0.158474</td>\n",
       "      <td>0.089964</td>\n",
       "      <td>0.074061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.180999</td>\n",
       "      <td>0.121683</td>\n",
       "      <td>0.107496</td>\n",
       "      <td>0.098149</td>\n",
       "      <td>0.101712</td>\n",
       "      <td>0.096460</td>\n",
       "      <td>0.084980</td>\n",
       "      <td>0.079546</td>\n",
       "      <td>0.070920</td>\n",
       "      <td>0.071008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.070053</td>\n",
       "      <td>0.196452</td>\n",
       "      <td>0.102357</td>\n",
       "      <td>0.162368</td>\n",
       "      <td>0.098449</td>\n",
       "      <td>0.177403</td>\n",
       "      <td>0.068557</td>\n",
       "      <td>0.087160</td>\n",
       "      <td>0.045305</td>\n",
       "      <td>0.054760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.046835</td>\n",
       "      <td>0.082876</td>\n",
       "      <td>0.066897</td>\n",
       "      <td>0.116783</td>\n",
       "      <td>0.086434</td>\n",
       "      <td>0.181181</td>\n",
       "      <td>0.087874</td>\n",
       "      <td>0.239009</td>\n",
       "      <td>0.091568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067022</td>\n",
       "      <td>0.170273</td>\n",
       "      <td>0.072422</td>\n",
       "      <td>0.126423</td>\n",
       "      <td>0.088229</td>\n",
       "      <td>0.141403</td>\n",
       "      <td>0.079299</td>\n",
       "      <td>0.116769</td>\n",
       "      <td>0.054092</td>\n",
       "      <td>0.087706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56263</th>\n",
       "      <td>0.143450</td>\n",
       "      <td>0.117778</td>\n",
       "      <td>0.150787</td>\n",
       "      <td>0.132649</td>\n",
       "      <td>0.143818</td>\n",
       "      <td>0.096034</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>0.061112</td>\n",
       "      <td>0.103331</td>\n",
       "      <td>0.054554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56264</th>\n",
       "      <td>0.101284</td>\n",
       "      <td>0.095192</td>\n",
       "      <td>0.137118</td>\n",
       "      <td>0.117579</td>\n",
       "      <td>0.121196</td>\n",
       "      <td>0.093661</td>\n",
       "      <td>0.099221</td>\n",
       "      <td>0.068079</td>\n",
       "      <td>0.094798</td>\n",
       "      <td>0.056980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56265</th>\n",
       "      <td>0.048547</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>0.080836</td>\n",
       "      <td>0.088613</td>\n",
       "      <td>0.116047</td>\n",
       "      <td>0.115507</td>\n",
       "      <td>0.127424</td>\n",
       "      <td>0.121010</td>\n",
       "      <td>0.131778</td>\n",
       "      <td>0.108365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56266</th>\n",
       "      <td>0.098536</td>\n",
       "      <td>0.246640</td>\n",
       "      <td>0.069629</td>\n",
       "      <td>0.122161</td>\n",
       "      <td>0.073359</td>\n",
       "      <td>0.108407</td>\n",
       "      <td>0.065999</td>\n",
       "      <td>0.087952</td>\n",
       "      <td>0.055602</td>\n",
       "      <td>0.076378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56267</th>\n",
       "      <td>0.037645</td>\n",
       "      <td>0.028566</td>\n",
       "      <td>0.058763</td>\n",
       "      <td>0.052605</td>\n",
       "      <td>0.104851</td>\n",
       "      <td>0.099547</td>\n",
       "      <td>0.128354</td>\n",
       "      <td>0.163130</td>\n",
       "      <td>0.144177</td>\n",
       "      <td>0.183456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56268 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       20대 남성 선호도 점수  20대 여성 선호도 점수  30대 남성 선호도 점수  30대 여성 선호도 점수  \\\n",
       "0           0.041315       0.054925       0.062113       0.069643   \n",
       "1           0.180999       0.121683       0.107496       0.098149   \n",
       "2           0.070053       0.196452       0.102357       0.162368   \n",
       "3           0.044321       0.046835       0.082876       0.066897   \n",
       "4           0.067022       0.170273       0.072422       0.126423   \n",
       "...              ...            ...            ...            ...   \n",
       "56263       0.143450       0.117778       0.150787       0.132649   \n",
       "56264       0.101284       0.095192       0.137118       0.117579   \n",
       "56265       0.048547       0.060623       0.080836       0.088613   \n",
       "56266       0.098536       0.246640       0.069629       0.122161   \n",
       "56267       0.037645       0.028566       0.058763       0.052605   \n",
       "\n",
       "       40대 남성 선호도 점수  40대 여성 선호도 점수  50대 남성 선호도 점수  50대 여성 선호도 점수  \\\n",
       "0           0.114829       0.180720       0.177137       0.158474   \n",
       "1           0.101712       0.096460       0.084980       0.079546   \n",
       "2           0.098449       0.177403       0.068557       0.087160   \n",
       "3           0.116783       0.086434       0.181181       0.087874   \n",
       "4           0.088229       0.141403       0.079299       0.116769   \n",
       "...              ...            ...            ...            ...   \n",
       "56263       0.143818       0.096034       0.108140       0.061112   \n",
       "56264       0.121196       0.093661       0.099221       0.068079   \n",
       "56265       0.116047       0.115507       0.127424       0.121010   \n",
       "56266       0.073359       0.108407       0.065999       0.087952   \n",
       "56267       0.104851       0.099547       0.128354       0.163130   \n",
       "\n",
       "       60대 남성 선호도 점수  60대 여성 선호도 점수  \n",
       "0           0.089964       0.074061  \n",
       "1           0.070920       0.071008  \n",
       "2           0.045305       0.054760  \n",
       "3           0.239009       0.091568  \n",
       "4           0.054092       0.087706  \n",
       "...              ...            ...  \n",
       "56263       0.103331       0.054554  \n",
       "56264       0.094798       0.056980  \n",
       "56265       0.131778       0.108365  \n",
       "56266       0.055602       0.076378  \n",
       "56267       0.144177       0.183456  \n",
       "\n",
       "[56268 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "pressed-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_score = y_train.iloc[:, 12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "wireless-badge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20대 남성 선호도 점수</th>\n",
       "      <th>20대 여성 선호도 점수</th>\n",
       "      <th>30대 남성 선호도 점수</th>\n",
       "      <th>30대 여성 선호도 점수</th>\n",
       "      <th>40대 남성 선호도 점수</th>\n",
       "      <th>40대 여성 선호도 점수</th>\n",
       "      <th>50대 남성 선호도 점수</th>\n",
       "      <th>50대 여성 선호도 점수</th>\n",
       "      <th>60대 남성 선호도 점수</th>\n",
       "      <th>60대 여성 선호도 점수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041312</td>\n",
       "      <td>0.113754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060858</td>\n",
       "      <td>0.112415</td>\n",
       "      <td>0.124614</td>\n",
       "      <td>0.262377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.092382</td>\n",
       "      <td>0.104007</td>\n",
       "      <td>0.071597</td>\n",
       "      <td>0.109999</td>\n",
       "      <td>0.091931</td>\n",
       "      <td>0.106132</td>\n",
       "      <td>0.125492</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.097320</td>\n",
       "      <td>0.143339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119632</td>\n",
       "      <td>0.338576</td>\n",
       "      <td>0.128006</td>\n",
       "      <td>0.413786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054057</td>\n",
       "      <td>0.087421</td>\n",
       "      <td>0.115681</td>\n",
       "      <td>0.026710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028234</td>\n",
       "      <td>0.119883</td>\n",
       "      <td>0.056268</td>\n",
       "      <td>0.107681</td>\n",
       "      <td>0.086296</td>\n",
       "      <td>0.174232</td>\n",
       "      <td>0.102733</td>\n",
       "      <td>0.164393</td>\n",
       "      <td>0.038242</td>\n",
       "      <td>0.122037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56263</th>\n",
       "      <td>0.367905</td>\n",
       "      <td>0.124260</td>\n",
       "      <td>0.171079</td>\n",
       "      <td>0.069168</td>\n",
       "      <td>0.183054</td>\n",
       "      <td>0.084533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56264</th>\n",
       "      <td>0.109225</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.114278</td>\n",
       "      <td>0.146310</td>\n",
       "      <td>0.135864</td>\n",
       "      <td>0.069015</td>\n",
       "      <td>0.069549</td>\n",
       "      <td>0.036609</td>\n",
       "      <td>0.172594</td>\n",
       "      <td>0.063552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56265</th>\n",
       "      <td>0.028774</td>\n",
       "      <td>0.087465</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>0.097373</td>\n",
       "      <td>0.128849</td>\n",
       "      <td>0.112391</td>\n",
       "      <td>0.029315</td>\n",
       "      <td>0.154307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56266</th>\n",
       "      <td>0.086716</td>\n",
       "      <td>0.288002</td>\n",
       "      <td>0.047044</td>\n",
       "      <td>0.127707</td>\n",
       "      <td>0.028764</td>\n",
       "      <td>0.073057</td>\n",
       "      <td>0.088346</td>\n",
       "      <td>0.046504</td>\n",
       "      <td>0.045675</td>\n",
       "      <td>0.168184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56267</th>\n",
       "      <td>0.025021</td>\n",
       "      <td>0.018592</td>\n",
       "      <td>0.039559</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>0.087386</td>\n",
       "      <td>0.119811</td>\n",
       "      <td>0.166387</td>\n",
       "      <td>0.173966</td>\n",
       "      <td>0.267876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56268 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       20대 남성 선호도 점수  20대 여성 선호도 점수  30대 남성 선호도 점수  30대 여성 선호도 점수  \\\n",
       "0           0.000000       0.041312       0.113754       0.000000   \n",
       "1           0.092382       0.104007       0.071597       0.109999   \n",
       "2           0.000000       0.000000       0.119632       0.338576   \n",
       "3           0.348746       0.000000       0.054057       0.087421   \n",
       "4           0.028234       0.119883       0.056268       0.107681   \n",
       "...              ...            ...            ...            ...   \n",
       "56263       0.367905       0.124260       0.171079       0.069168   \n",
       "56264       0.109225       0.083004       0.114278       0.146310   \n",
       "56265       0.028774       0.087465       0.093660       0.097373   \n",
       "56266       0.086716       0.288002       0.047044       0.127707   \n",
       "56267       0.025021       0.018592       0.039559       0.032929   \n",
       "\n",
       "       40대 남성 선호도 점수  40대 여성 선호도 점수  50대 남성 선호도 점수  50대 여성 선호도 점수  \\\n",
       "0           0.060858       0.112415       0.124614       0.262377   \n",
       "1           0.091931       0.106132       0.125492       0.057800   \n",
       "2           0.128006       0.413786       0.000000       0.000000   \n",
       "3           0.115681       0.026710       0.000000       0.000000   \n",
       "4           0.086296       0.174232       0.102733       0.164393   \n",
       "...              ...            ...            ...            ...   \n",
       "56263       0.183054       0.084533       0.000000       0.000000   \n",
       "56264       0.135864       0.069015       0.069549       0.036609   \n",
       "56265       0.128849       0.112391       0.029315       0.154307   \n",
       "56266       0.028764       0.073057       0.088346       0.046504   \n",
       "56267       0.068472       0.087386       0.119811       0.166387   \n",
       "\n",
       "       60대 남성 선호도 점수  60대 여성 선호도 점수  \n",
       "0           0.000000       0.284671  \n",
       "1           0.097320       0.143339  \n",
       "2           0.000000       0.000000  \n",
       "3           0.367385       0.000000  \n",
       "4           0.038242       0.122037  \n",
       "...              ...            ...  \n",
       "56263       0.000000       0.000000  \n",
       "56264       0.172594       0.063552  \n",
       "56265       0.000000       0.267868  \n",
       "56266       0.045675       0.168184  \n",
       "56267       0.173966       0.267876  \n",
       "\n",
       "[56268 rows x 10 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "caring-boost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10582"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(mean_squared_error(y_train_score, y_train_score_test)**0.5, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
